{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPn9MS64vwoeGfdJizUSez5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIS-SG/ai_lab_224n_NLP/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xSaYF9x15az"
      },
      "source": [
        "# 케라스(Keras)로 RNN 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUTGfweHgMew",
        "outputId": "08c32ca6-3a19-45e7-9e0b-41c1e34c0b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(2,10)))\n",
        "# model.add(SimpleRNN(3, input_length=2, input_dim=10))\n",
        "model.summary()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLoKHwuw0khL"
      },
      "source": [
        "#### 출력값이 (batch_size, output_dim) 크기의 2D 텐서일 떄, output_dimd은 hidden_size의 값인 3입니다.\n",
        "\n",
        "#### 이 경우 batch_size를 현 단계에서는 알 수 없으므로 (None, 3)이 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym23JWvvz1T_",
        "outputId": "af203f14-f725-4c4a-a686-527b5726ab90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# batch_size를 미리 정의\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (8, 3)                    42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLrKfeDGz2X3",
        "outputId": "ccc7d0c4-9b4e-4852-93ce-c3bb78cc9f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (8, 2, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEQtYNbg2Crw"
      },
      "source": [
        "# 파이썬으로 RNN 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ztz3w42F2O"
      },
      "source": [
        "$$ h_t = tanh(W_xX_t + W_hh_{t-1} + b) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuQ2dzG41cST",
        "outputId": "a26e8610-ac3b-4daf-8ea3-4170a940d209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "# 아래의 코드는 의사 코드(pseudocode)로 실제 동작하는 코드가 아님. \n",
        "\n",
        "hidden_state_t = 0 # 초기 은닉 상태를 0(벡터)로 초기화\n",
        "for input_t in input_length: # 각 시점마다 입력을 받는다.\n",
        "    output_t = tanh(input_t, hidden_state_t) # 각 시점에 대해서 입력과 은닉 상태를 가지고 연산\n",
        "    hidden_state_t = output_t # 계산 결과는 현재 시점의 은닉 상태가 된다."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-701191082f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhidden_state_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# 초기 은닉 상태를 0(벡터)로 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minput_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 각 시점마다 입력을 받는다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 각 시점에 대해서 입력과 은닉 상태를 가지고 연산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mhidden_state_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_t\u001b[0m \u001b[0;31m# 계산 결과는 현재 시점의 은닉 상태가 된다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_length' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggbe0Ufa3kL-"
      },
      "source": [
        "- input_t와 hidden_sate_t(이전 상태의 은닉 상태)를 입력으로 할성화 함수인 하이퍼볼릭탄젠트 함수를 통해 현 시점의 hidden_state_t를 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imvov76G2nm6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
        "input_dim = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
        "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
        "\n",
        "inputs = np.random.random((timesteps, input_dim)) # 입력에 해당되는 2D 텐서\n",
        "\n",
        "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화\n",
        "# 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6i0N8_Z3pdB",
        "outputId": "bae35132-76d3-41f9-bc6a-e3ae191c610a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(hidden_state_t)\n",
        "# 8의 크기를 가지는 은닉 상태. 현재는 초기 은닉 상태로 모든 차원이 0의 값을 가짐."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuyW3OFh4E9k"
      },
      "source": [
        "# 가중치와 편향 정의\n",
        "\n",
        "Wx = np.random.random((hidden_size, input_dim))  \n",
        "# (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
        "Wh = np.random.random((hidden_size, hidden_size)) \n",
        "# (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
        "b = np.random.random((hidden_size,)) \n",
        "# (8,)크기의 1D 텐서 생성. 이 값은 편향(bias)."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoRbEug54OCs",
        "outputId": "b74e40ab-36ca-4b6a-a09c-23f74b4d9825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(np.shape(Wx)) # (8,4)\n",
        "print(np.shape(Wh)) # (8,8)\n",
        "print(np.shape(b)) # (8,)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8, 4)\n",
            "(8, 8)\n",
            "(8,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bq054Jr4X5O",
        "outputId": "18e829c3-884a-4618-d900-3aa97a63b831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RNN 층 동작\n",
        "total_hidden_states = []\n",
        "\n",
        "# 메모리 셀 동작\n",
        "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n",
        "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) \n",
        "  # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  total_hidden_states.append(list(output_t)) \n",
        "  # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
        "  print(np.shape(total_hidden_states)) \n",
        "  # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
        "# 출력 시 값을 깔끔하게 해준다.\n",
        "\n",
        "print(total_hidden_states) \n",
        "# (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 8)\n",
            "(2, 8)\n",
            "(3, 8)\n",
            "(4, 8)\n",
            "(5, 8)\n",
            "(6, 8)\n",
            "(7, 8)\n",
            "(8, 8)\n",
            "(9, 8)\n",
            "(10, 8)\n",
            "[[0.95547972 0.90902415 0.92966985 0.9414954  0.78944766 0.86465435\n",
            "  0.91257602 0.90299818]\n",
            " [0.99997039 0.99878217 0.99995495 0.99999877 0.99999443 0.99991387\n",
            "  0.99974611 0.99964576]\n",
            " [0.999991   0.99970602 0.99999257 0.9999998  0.9999988  0.99997581\n",
            "  0.9999545  0.99992558]\n",
            " [0.99999471 0.999634   0.99999727 0.99999977 0.99999892 0.9999758\n",
            "  0.99996753 0.99996552]\n",
            " [0.99999103 0.99942345 0.99999364 0.9999993  0.99999922 0.99995984\n",
            "  0.99996303 0.9999594 ]\n",
            " [0.99999604 0.99983088 0.99999735 0.9999998  0.99999955 0.99998539\n",
            "  0.99998283 0.99997431]\n",
            " [0.9999902  0.99935662 0.99999466 0.99999946 0.99999875 0.99995612\n",
            "  0.9999563  0.99995747]\n",
            " [0.99999799 0.99981596 0.99999595 0.99999986 0.9999997  0.99999105\n",
            "  0.99996987 0.99993822]\n",
            " [0.99999736 0.99982646 0.99999749 0.99999984 0.99999962 0.99998853\n",
            "  0.99998003 0.99996827]\n",
            " [0.99998092 0.99889977 0.99997273 0.9999989  0.9999988  0.99993395\n",
            "  0.99990045 0.9998623 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO2SEL3CYfk8"
      },
      "source": [
        "# RNN을 이용한 텍스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds4nBCbZ5P2A",
        "outputId": "bf72fb36-0505-4bdd-c890-c5fbf3d54a41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 예제로 언급한 3개의 한국어 문장을 저장\n",
        "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
        "그의 말이 법이다\\n\n",
        "가는 말이 고와야 오는 말이 곱다\\n\"\"\"\n",
        "\n",
        "# 단어 집합을 생성하고 크기를 확인\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts([text])\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# 케라스 토크나이저의 정수 인코딩은 인덱스가 1부터 시작하지만,\n",
        "# 케라스 원-핫 인코딩에서 배열의 인덱스가 0부터 시작하기 때문에\n",
        "# 배열의 크기를 실제 단어 집합의 크기보다 +1로 생성해야하므로 미리 +1 선언 \n",
        "print('단어 집합의 크기 : %d' % vocab_size) # 단어 집합의 크기 : 12\n",
        "\n",
        "# 각 단어와 단어에 부여된 정수 인덱스 출력\n",
        "print(t.word_index)\n",
        "# {'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 12\n",
            "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrRlcCB9YyH1",
        "outputId": "24a1ae6c-9360-4a48-8cf8-a3ff65136cd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 훈련 데이터 만들기\n",
        "sequences = list()\n",
        "for line in text.split('\\n'): # Wn을 기준으로 문장 토큰화\n",
        "    encoded = t.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print('학습에 사용할 샘플의 개수: %d' % len(sequences)) # 학습에 사용할 샘플의 개수: 11\n",
        "\n",
        "print(sequences)\n",
        "# [[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습에 사용할 샘플의 개수: 11\n",
            "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgRI0hBAZR2h",
        "outputId": "8463a5eb-aaee-4d91-8e29-1d226f6ae4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# 전체 샘플에 대해서 길이를 일치 시켜주기\n",
        "max_len=max(len(l) for l in sequences) #모든 샘플에서 길이가 가장 긴 샘플의 길이 출력\n",
        "print('샘플의 최대 길이 : {}'.format(max_len)) # 샘플의 최대 길이 : 6 \n",
        "\n",
        "# 전체 샘플의 길이를 6으로 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences)\n",
        "\n",
        "# 레이블 분리\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]\n",
        "# 리스트의 마지막 값을 제외하고 저장한 것은 X\n",
        "# 리스트의 마지막 값만 저장한 것은 y. 이는 레이블에 해당됨\n",
        "print(X)\n",
        "print(y) # 모든 샘플에 대한 레이블 출력"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 6\n",
            "[[ 0  0  0  0  2  3]\n",
            " [ 0  0  0  2  3  1]\n",
            " [ 0  0  2  3  1  4]\n",
            " [ 0  2  3  1  4  5]\n",
            " [ 0  0  0  0  6  1]\n",
            " [ 0  0  0  6  1  7]\n",
            " [ 0  0  0  0  8  1]\n",
            " [ 0  0  0  8  1  9]\n",
            " [ 0  0  8  1  9 10]\n",
            " [ 0  8  1  9 10  1]\n",
            " [ 8  1  9 10  1 11]]\n",
            "[[ 0  0  0  0  2]\n",
            " [ 0  0  0  2  3]\n",
            " [ 0  0  2  3  1]\n",
            " [ 0  2  3  1  4]\n",
            " [ 0  0  0  0  6]\n",
            " [ 0  0  0  6  1]\n",
            " [ 0  0  0  0  8]\n",
            " [ 0  0  0  8  1]\n",
            " [ 0  0  8  1  9]\n",
            " [ 0  8  1  9 10]\n",
            " [ 8  1  9 10  1]]\n",
            "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBbN1LNVZ_v6",
        "outputId": "c7c8f9b9-cf15-4912-9c64-7b5817afacb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 원-핫 인코딩 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Z8-ZY3bcfJ"
      },
      "source": [
        "### 모델 설계하기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AIQUKStbaQ4",
        "outputId": "4cbd2812-c8b1-4fa9-e586-551dbf30601b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
        "\n",
        "# 임베딩 벡터는 10차원을 가지고 32의 은닉 상태 크기를 가지는 바닐라 RNN을 사용\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) # 레이블을 분리하였으므로 이제 X의 길이는 5\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 0s - loss: 2.4671 - accuracy: 0.2727\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 2.4549 - accuracy: 0.2727\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 2.4426 - accuracy: 0.3636\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 2.4302 - accuracy: 0.4545\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 2.4175 - accuracy: 0.4545\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.4044 - accuracy: 0.5455\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.3909 - accuracy: 0.5455\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.3767 - accuracy: 0.5455\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.3620 - accuracy: 0.5455\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 2.3465 - accuracy: 0.5455\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 2.3304 - accuracy: 0.5455\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 2.3134 - accuracy: 0.5455\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 2.2955 - accuracy: 0.4545\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 2.2768 - accuracy: 0.4545\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 2.2572 - accuracy: 0.4545\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 2.2368 - accuracy: 0.3636\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 2.2154 - accuracy: 0.3636\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 2.1932 - accuracy: 0.3636\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 2.1703 - accuracy: 0.3636\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 2.1468 - accuracy: 0.3636\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 2.1227 - accuracy: 0.3636\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 2.0982 - accuracy: 0.3636\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 2.0736 - accuracy: 0.3636\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 2.0489 - accuracy: 0.3636\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 2.0246 - accuracy: 0.3636\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 2.0008 - accuracy: 0.3636\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.9776 - accuracy: 0.3636\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.9554 - accuracy: 0.3636\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.9342 - accuracy: 0.3636\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.9142 - accuracy: 0.3636\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.8952 - accuracy: 0.3636\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.8773 - accuracy: 0.3636\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.8601 - accuracy: 0.3636\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.8436 - accuracy: 0.3636\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.8274 - accuracy: 0.3636\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.8113 - accuracy: 0.3636\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.7951 - accuracy: 0.3636\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.7787 - accuracy: 0.3636\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.7619 - accuracy: 0.3636\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.7447 - accuracy: 0.3636\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.7271 - accuracy: 0.3636\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.7092 - accuracy: 0.3636\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.6911 - accuracy: 0.3636\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.6727 - accuracy: 0.3636\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.6542 - accuracy: 0.4545\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6355 - accuracy: 0.4545\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6167 - accuracy: 0.4545\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.5978 - accuracy: 0.4545\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.5787 - accuracy: 0.4545\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.5592 - accuracy: 0.5455\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.5395 - accuracy: 0.5455\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.5194 - accuracy: 0.5455\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.4989 - accuracy: 0.5455\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.4780 - accuracy: 0.5455\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.4568 - accuracy: 0.5455\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.4351 - accuracy: 0.5455\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.4131 - accuracy: 0.5455\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.3909 - accuracy: 0.5455\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.3685 - accuracy: 0.5455\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.3459 - accuracy: 0.5455\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.3232 - accuracy: 0.5455\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.3006 - accuracy: 0.5455\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.2779 - accuracy: 0.5455\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.2554 - accuracy: 0.5455\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.2329 - accuracy: 0.5455\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.2106 - accuracy: 0.5455\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.1885 - accuracy: 0.5455\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.1666 - accuracy: 0.6364\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.1449 - accuracy: 0.6364\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.1234 - accuracy: 0.6364\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.1022 - accuracy: 0.6364\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.0812 - accuracy: 0.6364\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.0605 - accuracy: 0.6364\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.0400 - accuracy: 0.6364\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.0199 - accuracy: 0.7273\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.0001 - accuracy: 0.7273\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.9807 - accuracy: 0.7273\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.9615 - accuracy: 0.7273\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.9427 - accuracy: 0.7273\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.9242 - accuracy: 0.7273\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.9060 - accuracy: 0.7273\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.8881 - accuracy: 0.7273\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.8706 - accuracy: 0.7273\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.8533 - accuracy: 0.8182\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.8363 - accuracy: 0.8182\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.8196 - accuracy: 0.8182\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.8032 - accuracy: 0.8182\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.7871 - accuracy: 0.8182\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.7712 - accuracy: 0.8182\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.7556 - accuracy: 0.8182\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.7403 - accuracy: 0.8182\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.7252 - accuracy: 0.8182\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.7104 - accuracy: 0.8182\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.6958 - accuracy: 0.8182\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.6815 - accuracy: 0.8182\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.6675 - accuracy: 0.8182\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.6536 - accuracy: 0.8182\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.6401 - accuracy: 0.8182\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.6267 - accuracy: 0.8182\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.6136 - accuracy: 0.8182\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.6007 - accuracy: 0.8182\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.5881 - accuracy: 0.8182\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.5757 - accuracy: 0.9091\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.5635 - accuracy: 0.9091\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.5516 - accuracy: 0.9091\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.5399 - accuracy: 0.9091\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.5284 - accuracy: 0.9091\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.5172 - accuracy: 0.9091\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.5062 - accuracy: 0.9091\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.4954 - accuracy: 0.9091\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.4848 - accuracy: 0.9091\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.4745 - accuracy: 0.9091\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.4644 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.4545 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.4449 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.4354 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.4262 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.4171 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.4083 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.3997 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.3912 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.3829 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.3749 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.3670 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.3593 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.3517 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.3444 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.3372 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.3301 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.3233 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.3166 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.3100 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.3036 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.2974 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.2913 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.2853 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.2795 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.2738 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.2682 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.2628 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.2575 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.2523 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.2472 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.2423 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.2374 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.2327 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.2281 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.2236 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.2191 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.2148 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.2106 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.2065 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.2025 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.1985 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.1946 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.1909 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.1872 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.1836 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.1800 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.1766 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.1732 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.1699 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.1667 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.1635 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.1604 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.1574 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.1544 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.1515 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.1487 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.1459 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.1432 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.1406 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.1380 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.1354 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.1329 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.1305 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.1281 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.1258 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.1235 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.1213 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.1191 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.1170 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.1149 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.1129 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.1109 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.1090 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.1071 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.1052 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.1034 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.1017 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.0999 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.0982 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.0966 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.0950 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.0934 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.0919 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.0904 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.0889 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.0860 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb72468b1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slJHOi40b71a",
        "outputId": "71d9ec96-58bd-4a69-cc4a-96ca43ffdba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번 반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=5, padding='pre') # 데이터에 대한 패딩\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "    # 입력한 X(현재 단어)에 대해서 Y를 예측하고 Y(예측한 단어)를 result에 저장.\n",
        "        for word, index in t.word_index.items(): \n",
        "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "                break # 해당 단어가 예측 단어이므로 break\n",
        "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
        "    # for문이므로 이 행동을 다시 반복\n",
        "    sentence = init_word + sentence\n",
        "    return sentence\n",
        "\n",
        "print(sentence_generation(model, t, '경마장에', 4))\n",
        "# '경마장에' 라는 단어 뒤에는 총 4개의 단어가 있으므로 4번 예측\n",
        "\n",
        "print(sentence_generation(model, t, '그의', 2)) #   2번 예측\n",
        "\n",
        "print(sentence_generation(model, t, '가는', 5)) # 5번 예측"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "경마장에 있는 말이 뛰고 있다\n",
            "그의 말이 법이다\n",
            "가는 말이 고와야 오는 말이 곱다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_eUS1X7c6RX"
      },
      "source": [
        "# LSTM을 이용하여 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAfTF0xWc-Bd"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnQcHlRdcC59",
        "outputId": "e05cebdf-06bc-4f52-ec80-26cd1116cd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "df=pd.read_csv('ArticlesApril2018.csv')\n",
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>articleWordCount</th>\n",
              "      <th>byline</th>\n",
              "      <th>documentType</th>\n",
              "      <th>headline</th>\n",
              "      <th>keywords</th>\n",
              "      <th>multimedia</th>\n",
              "      <th>newDesk</th>\n",
              "      <th>printPage</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>sectionName</th>\n",
              "      <th>snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>typeOfMaterial</th>\n",
              "      <th>webURL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5adf6684068401528a2aa69b</td>\n",
              "      <td>781</td>\n",
              "      <td>By JOHN BRANCH</td>\n",
              "      <td>article</td>\n",
              "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
              "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
              "      <td>68</td>\n",
              "      <td>Sports</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:16:49</td>\n",
              "      <td>Pro Football</td>\n",
              "      <td>“I understand that they could meet with us, pa...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5adf653f068401528a2aa697</td>\n",
              "      <td>656</td>\n",
              "      <td>By LISA FRIEDMAN</td>\n",
              "      <td>article</td>\n",
              "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
              "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
              "      <td>68</td>\n",
              "      <td>Climate</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 17:11:21</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>The agency plans to publish a new regulation T...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5adf4626068401528a2aa628</td>\n",
              "      <td>2427</td>\n",
              "      <td>By PETE WELLS</td>\n",
              "      <td>article</td>\n",
              "      <td>The New Noma, Explained</td>\n",
              "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
              "      <td>66</td>\n",
              "      <td>Dining</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:58:44</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>What’s it like to eat at the second incarnatio...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5adf40d2068401528a2aa619</td>\n",
              "      <td>626</td>\n",
              "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
              "      <td>68</td>\n",
              "      <td>Washington</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:35:57</td>\n",
              "      <td>Europe</td>\n",
              "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5adf3d64068401528a2aa60f</td>\n",
              "      <td>815</td>\n",
              "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
              "      <td>article</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
              "      <td>68</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-24 14:21:21</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>News</td>\n",
              "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  articleID  ...                                             webURL\n",
              "0  5adf6684068401528a2aa69b  ...  https://www.nytimes.com/2018/04/24/sports/foot...\n",
              "1  5adf653f068401528a2aa697  ...  https://www.nytimes.com/2018/04/24/climate/epa...\n",
              "2  5adf4626068401528a2aa628  ...  https://www.nytimes.com/2018/04/24/dining/noma...\n",
              "3  5adf40d2068401528a2aa619  ...  https://www.nytimes.com/2018/04/24/world/europ...\n",
              "4  5adf3d64068401528a2aa60f  ...  https://www.nytimes.com/2018/04/24/world/canad...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhAVlnUoflZB",
        "outputId": "ff790f8a-de35-482a-c63b-eec7ced98603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('열의 개수: ',len(df.columns))\n",
        "print(df.columns)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "열의 개수:  15\n",
            "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
            "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
            "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBFo_3BIgCLe",
        "outputId": "511f2003-a9fa-433d-82f0-95a65fbac351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Null 값이 존재하는 지 확인\n",
        "df['headline'].isnull().values.any()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc9z1wkEgMSO",
        "outputId": "268bd7cb-5e52-48d6-854a-928d38b0172b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "headline = [] # 리스트 선언\n",
        "headline.extend(list(df.headline.values)) # 헤드라인의 값들을 리스트로 저장\n",
        "headline[:5] # 상위 5개만 출력"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'Unknown',\n",
              " 'Unknown']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YmjiJ2XgQHV",
        "outputId": "cb464a11-1a89-41f6-c8fc-6811380b9649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Unknown 값을 가진 샘플이 있어서 Null값은 아니지만 노이즈 데이터이므로 제거해줄 필요가 있다.\n",
        "# 제거하기 전에 현재 샘플의 개수를 확인해보고 제거 전, 후의 샘플의 개수 비교\n",
        "print('총 샘플의 개수 : {}'.format(len(headline))) # 현재 샘플의 개수 : 1324\n",
        "\n",
        "headline = [n for n in headline if n != \"Unknown\"] # Unknown 값을 가진 샘플 제거\n",
        "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline))) # 제거 후 샘플의 개수 : 1214\n",
        "\n",
        "headline[:5]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 개수 : 1214\n",
            "노이즈값 제거 후 샘플의 개수 : 1214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
              " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
              " 'The New Noma, Explained',\n",
              " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
              " 'Is School a Place for Self-Expression?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGGoWTLRgvnz",
        "outputId": "cbf9999e-685c-4721-d664-54a19c6f446c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 선택한 전처리는 구두점 제거와 단어의 소문자화입니다.\n",
        "# 전처리를 수행하고, 다시 샘플 5개를 출력한다.\n",
        "\n",
        "def repreprocessing(s):\n",
        "    s=s.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return ''.join(c for c in s if c not in punctuation).lower() # 구두점 제거와 동시에 소문자화\n",
        "\n",
        "text = [repreprocessing(x) for x in headline]\n",
        "text[:5]\n",
        "\n",
        "# 기존의 출력과 비교하면 모든 단어들이 소문자화되었으며 N.F.L.이나 Cheerleaders 등과 같이 기존에 구두점이 붙어있던 단어들에서 구두점 제거"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
              " 'epa to unveil a new rule its effect less science in policymaking',\n",
              " 'the new noma explained',\n",
              " 'how a bag of texas dirt  became a times tradition',\n",
              " 'is school a place for selfexpression']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF-OQRJ8hUPB",
        "outputId": "653562a9-05f0-4a48-9acb-3e2c530a403b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 단어 집합을 만들고 크기 비교\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(text)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print('단어 집합의 크기 : %d' % vocab_size) # 단어 집합의 크기 : 3494"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 3494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GZulw5FhUoC",
        "outputId": "1192f9d8-efb0-4650-d85c-efbb625eeb06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# 훈련 데이터 구성\n",
        "sequences = list()\n",
        "\n",
        "for line in text: # 1,214 개의 샘플에 대해서 샘플을 1개씩 가져온다.\n",
        "    encoded = t.texts_to_sequences([line])[0] # 각 샘플에 대한 정수 인코딩\n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "sequences[:11] # 11개의 샘플 출력"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[99, 269],\n",
              " [99, 269, 371],\n",
              " [99, 269, 371, 1115],\n",
              " [99, 269, 371, 1115, 582],\n",
              " [99, 269, 371, 1115, 582, 52],\n",
              " [99, 269, 371, 1115, 582, 52, 7],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
              " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
              " [100, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wTTcYquhh0N",
        "outputId": "9b57e2e1-f639-4e21-d3fe-4c2a4fd2e06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 어떤 정수가 어떤 단어를 의미하는지 알아보기 위해 인덱스로부터 단어를 찾는 index_to_word를 만든다\n",
        "index_to_word={}\n",
        "for key, value in t.word_index.items(): \n",
        "  # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "  index_to_word[value] = key\n",
        "\n",
        "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))\n",
        "# 빈도수 상위. 582번 단어 : offer"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "빈도수 상위 582번 단어 : offer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCZK8KpAip7W",
        "outputId": "a3872265-3aee-4009-db5a-a46eaaf9f0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# y데이터를 분리하기 전에 전체 샘플의 길이를 동일하게 만드는 패딩 작업을 수행\n",
        "# 패딩 작업을 수행하기 전에 가장 긴 샘플의 길이를 확인\n",
        "\n",
        "max_len=max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))\n",
        "# 샘플의 최대 길이 : 24\n",
        "\n",
        "#padding='pre'를 설정하면 샘플의 길이가 24보다 짧은 경우에 앞에 0으로 패딩\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "print(sequences[:3])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "샘플의 최대 길이 : 24\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0   99  269]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0   99  269  371]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0   99  269  371 1115]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJsdiDZUi7lf",
        "outputId": "ebe58ba2-7ed7-495c-b2cd-8d58136dbd73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# 맨 우측 단어만 레이블로 분리한다.\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]\n",
        "\n",
        "print(X[:3])\n",
        "# 맨 우측에 있던 정수값 269, 371, 1115가 사라진 것을 볼 수 있다.\n",
        "# 각 샘플의 길이가 24에서 23으로 줄었다.\n",
        "\n",
        "print(y[:3]) # 레이블\n",
        "# [ 269 317 1115]\n",
        "# 기존 훈련 데이터에서 맨 우측에 있던 정수들이 별도로 저장됨\n",
        "\n",
        "# 레이블 데이터 y에 대해서 원-핫 인코딩을 수행\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0  99 269]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  99 269 371]]\n",
            "[ 269  371 1115]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9I8gux5khBZ"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjVlTY_XjMWH",
        "outputId": "6cd7f0ec-f7c1-44a6-c7d7-de19121bbc7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
        "# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "244/244 - 7s - loss: 7.6370 - accuracy: 0.0287\n",
            "Epoch 2/200\n",
            "244/244 - 7s - loss: 7.1113 - accuracy: 0.0308\n",
            "Epoch 3/200\n",
            "244/244 - 7s - loss: 6.9760 - accuracy: 0.0329\n",
            "Epoch 4/200\n",
            "244/244 - 7s - loss: 6.8558 - accuracy: 0.0424\n",
            "Epoch 5/200\n",
            "244/244 - 7s - loss: 6.7061 - accuracy: 0.0423\n",
            "Epoch 6/200\n",
            "244/244 - 7s - loss: 6.5344 - accuracy: 0.0500\n",
            "Epoch 7/200\n",
            "244/244 - 7s - loss: 6.3412 - accuracy: 0.0523\n",
            "Epoch 8/200\n",
            "244/244 - 7s - loss: 6.1318 - accuracy: 0.0579\n",
            "Epoch 9/200\n",
            "244/244 - 7s - loss: 5.9313 - accuracy: 0.0672\n",
            "Epoch 10/200\n",
            "244/244 - 7s - loss: 5.7395 - accuracy: 0.0691\n",
            "Epoch 11/200\n",
            "244/244 - 7s - loss: 5.5555 - accuracy: 0.0755\n",
            "Epoch 12/200\n",
            "244/244 - 7s - loss: 5.3844 - accuracy: 0.0792\n",
            "Epoch 13/200\n",
            "244/244 - 7s - loss: 5.2232 - accuracy: 0.0824\n",
            "Epoch 14/200\n",
            "244/244 - 7s - loss: 5.0683 - accuracy: 0.0933\n",
            "Epoch 15/200\n",
            "244/244 - 7s - loss: 4.9202 - accuracy: 0.0969\n",
            "Epoch 16/200\n",
            "244/244 - 7s - loss: 4.7777 - accuracy: 0.1088\n",
            "Epoch 17/200\n",
            "244/244 - 7s - loss: 4.6437 - accuracy: 0.1224\n",
            "Epoch 18/200\n",
            "244/244 - 7s - loss: 4.5131 - accuracy: 0.1402\n",
            "Epoch 19/200\n",
            "244/244 - 7s - loss: 4.3843 - accuracy: 0.1561\n",
            "Epoch 20/200\n",
            "244/244 - 7s - loss: 4.2610 - accuracy: 0.1697\n",
            "Epoch 21/200\n",
            "244/244 - 7s - loss: 4.1441 - accuracy: 0.1910\n",
            "Epoch 22/200\n",
            "244/244 - 7s - loss: 4.0292 - accuracy: 0.2022\n",
            "Epoch 23/200\n",
            "244/244 - 7s - loss: 3.9169 - accuracy: 0.2222\n",
            "Epoch 24/200\n",
            "244/244 - 7s - loss: 3.8093 - accuracy: 0.2380\n",
            "Epoch 25/200\n",
            "244/244 - 7s - loss: 3.7057 - accuracy: 0.2532\n",
            "Epoch 26/200\n",
            "244/244 - 7s - loss: 3.6189 - accuracy: 0.2757\n",
            "Epoch 27/200\n",
            "244/244 - 7s - loss: 3.5134 - accuracy: 0.2887\n",
            "Epoch 28/200\n",
            "244/244 - 7s - loss: 3.4187 - accuracy: 0.3101\n",
            "Epoch 29/200\n",
            "244/244 - 7s - loss: 3.3273 - accuracy: 0.3283\n",
            "Epoch 30/200\n",
            "244/244 - 8s - loss: 3.2420 - accuracy: 0.3417\n",
            "Epoch 31/200\n",
            "244/244 - 7s - loss: 3.1596 - accuracy: 0.3579\n",
            "Epoch 32/200\n",
            "244/244 - 7s - loss: 3.0781 - accuracy: 0.3806\n",
            "Epoch 33/200\n",
            "244/244 - 7s - loss: 3.0026 - accuracy: 0.3909\n",
            "Epoch 34/200\n",
            "244/244 - 7s - loss: 2.9298 - accuracy: 0.4050\n",
            "Epoch 35/200\n",
            "244/244 - 7s - loss: 2.8560 - accuracy: 0.4196\n",
            "Epoch 36/200\n",
            "244/244 - 7s - loss: 2.7884 - accuracy: 0.4302\n",
            "Epoch 37/200\n",
            "244/244 - 7s - loss: 2.7229 - accuracy: 0.4409\n",
            "Epoch 38/200\n",
            "244/244 - 7s - loss: 2.6570 - accuracy: 0.4573\n",
            "Epoch 39/200\n",
            "244/244 - 8s - loss: 2.5942 - accuracy: 0.4666\n",
            "Epoch 40/200\n",
            "244/244 - 7s - loss: 2.5330 - accuracy: 0.4810\n",
            "Epoch 41/200\n",
            "244/244 - 7s - loss: 2.4764 - accuracy: 0.4948\n",
            "Epoch 42/200\n",
            "244/244 - 7s - loss: 2.4192 - accuracy: 0.5024\n",
            "Epoch 43/200\n",
            "244/244 - 7s - loss: 2.3649 - accuracy: 0.5110\n",
            "Epoch 44/200\n",
            "244/244 - 7s - loss: 2.3106 - accuracy: 0.5252\n",
            "Epoch 45/200\n",
            "244/244 - 7s - loss: 2.2604 - accuracy: 0.5294\n",
            "Epoch 46/200\n",
            "244/244 - 7s - loss: 2.2075 - accuracy: 0.5422\n",
            "Epoch 47/200\n",
            "244/244 - 7s - loss: 2.1605 - accuracy: 0.5562\n",
            "Epoch 48/200\n",
            "244/244 - 7s - loss: 2.1119 - accuracy: 0.5625\n",
            "Epoch 49/200\n",
            "244/244 - 7s - loss: 2.0671 - accuracy: 0.5693\n",
            "Epoch 50/200\n",
            "244/244 - 7s - loss: 2.0183 - accuracy: 0.5827\n",
            "Epoch 51/200\n",
            "244/244 - 7s - loss: 1.9754 - accuracy: 0.5903\n",
            "Epoch 52/200\n",
            "244/244 - 7s - loss: 1.9314 - accuracy: 0.5975\n",
            "Epoch 53/200\n",
            "244/244 - 7s - loss: 1.8899 - accuracy: 0.6069\n",
            "Epoch 54/200\n",
            "244/244 - 7s - loss: 1.8490 - accuracy: 0.6146\n",
            "Epoch 55/200\n",
            "244/244 - 7s - loss: 1.8072 - accuracy: 0.6272\n",
            "Epoch 56/200\n",
            "244/244 - 7s - loss: 1.7670 - accuracy: 0.6339\n",
            "Epoch 57/200\n",
            "244/244 - 7s - loss: 1.7318 - accuracy: 0.6403\n",
            "Epoch 58/200\n",
            "244/244 - 7s - loss: 1.6917 - accuracy: 0.6506\n",
            "Epoch 59/200\n",
            "244/244 - 7s - loss: 1.6563 - accuracy: 0.6613\n",
            "Epoch 60/200\n",
            "244/244 - 7s - loss: 1.6188 - accuracy: 0.6688\n",
            "Epoch 61/200\n",
            "244/244 - 7s - loss: 1.5841 - accuracy: 0.6732\n",
            "Epoch 62/200\n",
            "244/244 - 7s - loss: 1.5495 - accuracy: 0.6850\n",
            "Epoch 63/200\n",
            "244/244 - 7s - loss: 1.5163 - accuracy: 0.6878\n",
            "Epoch 64/200\n",
            "244/244 - 7s - loss: 1.4793 - accuracy: 0.6978\n",
            "Epoch 65/200\n",
            "244/244 - 7s - loss: 1.4510 - accuracy: 0.7004\n",
            "Epoch 66/200\n",
            "244/244 - 7s - loss: 1.4197 - accuracy: 0.7101\n",
            "Epoch 67/200\n",
            "244/244 - 7s - loss: 1.3873 - accuracy: 0.7164\n",
            "Epoch 68/200\n",
            "244/244 - 7s - loss: 1.3566 - accuracy: 0.7270\n",
            "Epoch 69/200\n",
            "244/244 - 7s - loss: 1.3280 - accuracy: 0.7302\n",
            "Epoch 70/200\n",
            "244/244 - 7s - loss: 1.3004 - accuracy: 0.7363\n",
            "Epoch 71/200\n",
            "244/244 - 7s - loss: 1.2719 - accuracy: 0.7418\n",
            "Epoch 72/200\n",
            "244/244 - 8s - loss: 1.2465 - accuracy: 0.7496\n",
            "Epoch 73/200\n",
            "244/244 - 8s - loss: 1.2176 - accuracy: 0.7557\n",
            "Epoch 74/200\n",
            "244/244 - 8s - loss: 1.1929 - accuracy: 0.7574\n",
            "Epoch 75/200\n",
            "244/244 - 7s - loss: 1.1668 - accuracy: 0.7632\n",
            "Epoch 76/200\n",
            "244/244 - 7s - loss: 1.1402 - accuracy: 0.7700\n",
            "Epoch 77/200\n",
            "244/244 - 7s - loss: 1.1187 - accuracy: 0.7769\n",
            "Epoch 78/200\n",
            "244/244 - 7s - loss: 1.0925 - accuracy: 0.7811\n",
            "Epoch 79/200\n",
            "244/244 - 7s - loss: 1.0689 - accuracy: 0.7843\n",
            "Epoch 80/200\n",
            "244/244 - 7s - loss: 1.0449 - accuracy: 0.7887\n",
            "Epoch 81/200\n",
            "244/244 - 8s - loss: 1.0247 - accuracy: 0.7932\n",
            "Epoch 82/200\n",
            "244/244 - 7s - loss: 1.0066 - accuracy: 0.7988\n",
            "Epoch 83/200\n",
            "244/244 - 7s - loss: 0.9870 - accuracy: 0.7996\n",
            "Epoch 84/200\n",
            "244/244 - 7s - loss: 0.9595 - accuracy: 0.8033\n",
            "Epoch 85/200\n",
            "244/244 - 7s - loss: 0.9411 - accuracy: 0.8087\n",
            "Epoch 86/200\n",
            "244/244 - 7s - loss: 0.9175 - accuracy: 0.8120\n",
            "Epoch 87/200\n",
            "244/244 - 7s - loss: 0.8990 - accuracy: 0.8149\n",
            "Epoch 88/200\n",
            "244/244 - 7s - loss: 0.8789 - accuracy: 0.8228\n",
            "Epoch 89/200\n",
            "244/244 - 7s - loss: 0.8610 - accuracy: 0.8224\n",
            "Epoch 90/200\n",
            "244/244 - 7s - loss: 0.8440 - accuracy: 0.8287\n",
            "Epoch 91/200\n",
            "244/244 - 7s - loss: 0.8262 - accuracy: 0.8312\n",
            "Epoch 92/200\n",
            "244/244 - 7s - loss: 0.8060 - accuracy: 0.8358\n",
            "Epoch 93/200\n",
            "244/244 - 7s - loss: 0.7915 - accuracy: 0.8379\n",
            "Epoch 94/200\n",
            "244/244 - 7s - loss: 0.7738 - accuracy: 0.8420\n",
            "Epoch 95/200\n",
            "244/244 - 7s - loss: 0.7560 - accuracy: 0.8445\n",
            "Epoch 96/200\n",
            "244/244 - 7s - loss: 0.7418 - accuracy: 0.8478\n",
            "Epoch 97/200\n",
            "244/244 - 7s - loss: 0.7272 - accuracy: 0.8497\n",
            "Epoch 98/200\n",
            "244/244 - 7s - loss: 0.7091 - accuracy: 0.8547\n",
            "Epoch 99/200\n",
            "244/244 - 7s - loss: 0.6947 - accuracy: 0.8567\n",
            "Epoch 100/200\n",
            "244/244 - 7s - loss: 0.6822 - accuracy: 0.8598\n",
            "Epoch 101/200\n",
            "244/244 - 7s - loss: 0.6673 - accuracy: 0.8631\n",
            "Epoch 102/200\n",
            "244/244 - 7s - loss: 0.6545 - accuracy: 0.8640\n",
            "Epoch 103/200\n",
            "244/244 - 7s - loss: 0.6411 - accuracy: 0.8680\n",
            "Epoch 104/200\n",
            "244/244 - 7s - loss: 0.6251 - accuracy: 0.8717\n",
            "Epoch 105/200\n",
            "244/244 - 7s - loss: 0.6121 - accuracy: 0.8730\n",
            "Epoch 106/200\n",
            "244/244 - 7s - loss: 0.5998 - accuracy: 0.8786\n",
            "Epoch 107/200\n",
            "244/244 - 7s - loss: 0.5877 - accuracy: 0.8793\n",
            "Epoch 108/200\n",
            "244/244 - 7s - loss: 0.5763 - accuracy: 0.8793\n",
            "Epoch 109/200\n",
            "244/244 - 7s - loss: 0.5653 - accuracy: 0.8835\n",
            "Epoch 110/200\n",
            "244/244 - 7s - loss: 0.5550 - accuracy: 0.8838\n",
            "Epoch 111/200\n",
            "244/244 - 7s - loss: 0.5431 - accuracy: 0.8889\n",
            "Epoch 112/200\n",
            "244/244 - 7s - loss: 0.5334 - accuracy: 0.8889\n",
            "Epoch 113/200\n",
            "244/244 - 7s - loss: 0.5247 - accuracy: 0.8908\n",
            "Epoch 114/200\n",
            "244/244 - 7s - loss: 0.5136 - accuracy: 0.8926\n",
            "Epoch 115/200\n",
            "244/244 - 7s - loss: 0.5048 - accuracy: 0.8949\n",
            "Epoch 116/200\n",
            "244/244 - 8s - loss: 0.4931 - accuracy: 0.8966\n",
            "Epoch 117/200\n",
            "244/244 - 7s - loss: 0.4827 - accuracy: 0.8977\n",
            "Epoch 118/200\n",
            "244/244 - 7s - loss: 0.4740 - accuracy: 0.8990\n",
            "Epoch 119/200\n",
            "244/244 - 7s - loss: 0.4664 - accuracy: 0.9002\n",
            "Epoch 120/200\n",
            "244/244 - 7s - loss: 0.4586 - accuracy: 0.8993\n",
            "Epoch 121/200\n",
            "244/244 - 7s - loss: 0.4508 - accuracy: 0.9030\n",
            "Epoch 122/200\n",
            "244/244 - 7s - loss: 0.4425 - accuracy: 0.9031\n",
            "Epoch 123/200\n",
            "244/244 - 8s - loss: 0.4421 - accuracy: 0.9027\n",
            "Epoch 124/200\n",
            "244/244 - 7s - loss: 0.4348 - accuracy: 0.9045\n",
            "Epoch 125/200\n",
            "244/244 - 7s - loss: 0.4215 - accuracy: 0.9059\n",
            "Epoch 126/200\n",
            "244/244 - 7s - loss: 0.4141 - accuracy: 0.9066\n",
            "Epoch 127/200\n",
            "244/244 - 7s - loss: 0.4072 - accuracy: 0.9099\n",
            "Epoch 128/200\n",
            "244/244 - 7s - loss: 0.4027 - accuracy: 0.9073\n",
            "Epoch 129/200\n",
            "244/244 - 7s - loss: 0.3963 - accuracy: 0.9112\n",
            "Epoch 130/200\n",
            "244/244 - 7s - loss: 0.3924 - accuracy: 0.9113\n",
            "Epoch 131/200\n",
            "244/244 - 7s - loss: 0.3858 - accuracy: 0.9120\n",
            "Epoch 132/200\n",
            "244/244 - 7s - loss: 0.3814 - accuracy: 0.9121\n",
            "Epoch 133/200\n",
            "244/244 - 7s - loss: 0.3763 - accuracy: 0.9099\n",
            "Epoch 134/200\n",
            "244/244 - 7s - loss: 0.3699 - accuracy: 0.9103\n",
            "Epoch 135/200\n",
            "244/244 - 7s - loss: 0.3710 - accuracy: 0.9108\n",
            "Epoch 136/200\n",
            "244/244 - 7s - loss: 0.3626 - accuracy: 0.9127\n",
            "Epoch 137/200\n",
            "244/244 - 7s - loss: 0.3562 - accuracy: 0.9129\n",
            "Epoch 138/200\n",
            "244/244 - 7s - loss: 0.3526 - accuracy: 0.9109\n",
            "Epoch 139/200\n",
            "244/244 - 7s - loss: 0.3498 - accuracy: 0.9144\n",
            "Epoch 140/200\n",
            "244/244 - 7s - loss: 0.3431 - accuracy: 0.9129\n",
            "Epoch 141/200\n",
            "244/244 - 7s - loss: 0.3434 - accuracy: 0.9141\n",
            "Epoch 142/200\n",
            "244/244 - 7s - loss: 0.3381 - accuracy: 0.9129\n",
            "Epoch 143/200\n",
            "244/244 - 7s - loss: 0.3341 - accuracy: 0.9139\n",
            "Epoch 144/200\n",
            "244/244 - 7s - loss: 0.3300 - accuracy: 0.9139\n",
            "Epoch 145/200\n",
            "244/244 - 7s - loss: 0.3541 - accuracy: 0.9105\n",
            "Epoch 146/200\n",
            "244/244 - 7s - loss: 0.3509 - accuracy: 0.9122\n",
            "Epoch 147/200\n",
            "244/244 - 7s - loss: 0.3237 - accuracy: 0.9162\n",
            "Epoch 148/200\n",
            "244/244 - 7s - loss: 0.3181 - accuracy: 0.9149\n",
            "Epoch 149/200\n",
            "244/244 - 7s - loss: 0.3151 - accuracy: 0.9152\n",
            "Epoch 150/200\n",
            "244/244 - 7s - loss: 0.3126 - accuracy: 0.9172\n",
            "Epoch 151/200\n",
            "244/244 - 7s - loss: 0.3110 - accuracy: 0.9162\n",
            "Epoch 152/200\n",
            "244/244 - 7s - loss: 0.3089 - accuracy: 0.9130\n",
            "Epoch 153/200\n",
            "244/244 - 7s - loss: 0.3066 - accuracy: 0.9154\n",
            "Epoch 154/200\n",
            "244/244 - 7s - loss: 0.3049 - accuracy: 0.9162\n",
            "Epoch 155/200\n",
            "244/244 - 7s - loss: 0.3031 - accuracy: 0.9159\n",
            "Epoch 156/200\n",
            "244/244 - 7s - loss: 0.3008 - accuracy: 0.9171\n",
            "Epoch 157/200\n",
            "244/244 - 7s - loss: 0.3015 - accuracy: 0.9148\n",
            "Epoch 158/200\n",
            "244/244 - 7s - loss: 0.2979 - accuracy: 0.9171\n",
            "Epoch 159/200\n",
            "244/244 - 8s - loss: 0.3017 - accuracy: 0.9135\n",
            "Epoch 160/200\n",
            "244/244 - 8s - loss: 0.3019 - accuracy: 0.9167\n",
            "Epoch 161/200\n",
            "244/244 - 7s - loss: 0.2944 - accuracy: 0.9139\n",
            "Epoch 162/200\n",
            "244/244 - 7s - loss: 0.3074 - accuracy: 0.9144\n",
            "Epoch 163/200\n",
            "244/244 - 7s - loss: 0.3183 - accuracy: 0.9141\n",
            "Epoch 164/200\n",
            "244/244 - 7s - loss: 0.2947 - accuracy: 0.9154\n",
            "Epoch 165/200\n",
            "244/244 - 7s - loss: 0.2881 - accuracy: 0.9158\n",
            "Epoch 166/200\n",
            "244/244 - 7s - loss: 0.2855 - accuracy: 0.9157\n",
            "Epoch 167/200\n",
            "244/244 - 7s - loss: 0.2841 - accuracy: 0.9172\n",
            "Epoch 168/200\n",
            "244/244 - 7s - loss: 0.2832 - accuracy: 0.9173\n",
            "Epoch 169/200\n",
            "244/244 - 9s - loss: 0.2819 - accuracy: 0.9171\n",
            "Epoch 170/200\n",
            "244/244 - 8s - loss: 0.2814 - accuracy: 0.9168\n",
            "Epoch 171/200\n",
            "244/244 - 7s - loss: 0.2797 - accuracy: 0.9159\n",
            "Epoch 172/200\n",
            "244/244 - 7s - loss: 0.2800 - accuracy: 0.9157\n",
            "Epoch 173/200\n",
            "244/244 - 7s - loss: 0.2793 - accuracy: 0.9155\n",
            "Epoch 174/200\n",
            "244/244 - 7s - loss: 0.2797 - accuracy: 0.9166\n",
            "Epoch 175/200\n",
            "244/244 - 7s - loss: 0.2780 - accuracy: 0.9154\n",
            "Epoch 176/200\n",
            "244/244 - 7s - loss: 0.2771 - accuracy: 0.9166\n",
            "Epoch 177/200\n",
            "244/244 - 7s - loss: 0.2777 - accuracy: 0.9170\n",
            "Epoch 178/200\n",
            "244/244 - 7s - loss: 0.2754 - accuracy: 0.9155\n",
            "Epoch 179/200\n",
            "244/244 - 7s - loss: 0.2759 - accuracy: 0.9163\n",
            "Epoch 180/200\n",
            "244/244 - 7s - loss: 0.2758 - accuracy: 0.9167\n",
            "Epoch 181/200\n",
            "244/244 - 7s - loss: 0.2875 - accuracy: 0.9135\n",
            "Epoch 182/200\n",
            "244/244 - 7s - loss: 0.3036 - accuracy: 0.9118\n",
            "Epoch 183/200\n",
            "244/244 - 7s - loss: 0.2801 - accuracy: 0.9158\n",
            "Epoch 184/200\n",
            "244/244 - 7s - loss: 0.2716 - accuracy: 0.9175\n",
            "Epoch 185/200\n",
            "244/244 - 7s - loss: 0.2697 - accuracy: 0.9173\n",
            "Epoch 186/200\n",
            "244/244 - 7s - loss: 0.2690 - accuracy: 0.9161\n",
            "Epoch 187/200\n",
            "244/244 - 7s - loss: 0.2692 - accuracy: 0.9166\n",
            "Epoch 188/200\n",
            "244/244 - 7s - loss: 0.2680 - accuracy: 0.9158\n",
            "Epoch 189/200\n",
            "244/244 - 7s - loss: 0.2687 - accuracy: 0.9145\n",
            "Epoch 190/200\n",
            "244/244 - 7s - loss: 0.2677 - accuracy: 0.9154\n",
            "Epoch 191/200\n",
            "244/244 - 7s - loss: 0.2671 - accuracy: 0.9164\n",
            "Epoch 192/200\n",
            "244/244 - 7s - loss: 0.2667 - accuracy: 0.9161\n",
            "Epoch 193/200\n",
            "244/244 - 7s - loss: 0.2661 - accuracy: 0.9164\n",
            "Epoch 194/200\n",
            "244/244 - 7s - loss: 0.2664 - accuracy: 0.9162\n",
            "Epoch 195/200\n",
            "244/244 - 7s - loss: 0.2653 - accuracy: 0.9182\n",
            "Epoch 196/200\n",
            "244/244 - 7s - loss: 0.2652 - accuracy: 0.9163\n",
            "Epoch 197/200\n",
            "244/244 - 7s - loss: 0.2668 - accuracy: 0.9153\n",
            "Epoch 198/200\n",
            "244/244 - 7s - loss: 0.2663 - accuracy: 0.9163\n",
            "Epoch 199/200\n",
            "244/244 - 7s - loss: 0.2670 - accuracy: 0.9164\n",
            "Epoch 200/200\n",
            "244/244 - 7s - loss: 0.2672 - accuracy: 0.9161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb7210b1e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocThJnfDkthx"
      },
      "source": [
        "# 각 단어의 임베딩 벡터는 10차원을 가지고, 128의 은닉 상태 크기를 가지는 LSTM을 사용한다.\n",
        "# 문장을 생성하는 함수 sentence_generation을 만들어서 문장을 생성\n",
        "\n",
        "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
        "    sentence = ''\n",
        "    for _ in range(n): # n번 반복\n",
        "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=23, padding='pre') # 데이터에 대한 패딩\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        for word, index in t.word_index.items(): \n",
        "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "                break # 해당 단어가 예측 단어이므로 break\n",
        "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
        "    # for문이므로 이 행동을 다시 반복\n",
        "    sentence = init_word + sentence\n",
        "    return sentence\n",
        "\n",
        "print(sentence_generation(model, t, 'i', 10))\n",
        "# 임의의 단어 'i'에 대해서 10개의 단어를 추가 생성\n",
        "\n",
        "print(sentence_generation(model, t, 'how', 10))\n",
        "# 임의의 단어 'how'에 대해서 10개의 단어를 추가 생성"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL1Bmr2Cstvk"
      },
      "source": [
        "# 글자 단위 RNN 언어 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N_nhMdMswz7"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6iqvQZqk7XW"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "f = open('11-0.txt', 'rb')\n",
        "lines=[]\n",
        "for line in f: # 데이터를 한 줄씩 읽는다.\n",
        "    line=line.strip() # strip()을 통해 \\r, \\n을 제거한다.\n",
        "    line=line.lower() # 소문자화.\n",
        "    line=line.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
        "    if len(line) > 0:\n",
        "        lines.append(line)\n",
        "f.close()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kagVj5j8tDNE",
        "outputId": "e9df739d-8230-40b8-bf9c-aed2c1fd57aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# 간단한 전처리가 수행된 lines란 이름의 리스트에 저장\n",
        "# 리스트에서 5개의 원소만 출력\n",
        "lines[:5]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and most',\n",
              " 'other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever.  you may copy it, give it away or re-use it under the terms of',\n",
              " 'the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZJ9XLFStbLO",
        "outputId": "ad482b04-2168-42bf-9a1d-0eece0bc87a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 각 원소는 문자열로 구성되어져 있는데, 특별히 의미있게 문장 토큰화가 된 상태는 아니다.\n",
        "# 하나의 문자열로 통합\n",
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 개수: %d' % len(text))\n",
        "# 문자열의 길이 또는 총 글자의 개수 : 158783"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 개수: 159821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJSjlqW_twqG",
        "outputId": "e54c96fc-ba9d-4ae0-97ec-96bf3c22a489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(text[:200])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN6nNSwKtzzr",
        "outputId": "5e976d48-fbaf-47c8-c7b4-169bf68aeaa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 문자열로부터 글자 집합 만들기\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size=len(char_vocab)\n",
        "print ('글자 집합의 크기 : {}'.format(vocab_size))\n",
        "# 글자 집합의 크기 : 57"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zFiMXdMuAaM",
        "outputId": "15c11253-b0a5-4a1a-cab2-1095a5de6ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 글자 집합에 인덱스를 부여하고 전부 출력\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '@': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'b': 32, 'c': 33, 'd': 34, 'e': 35, 'f': 36, 'g': 37, 'h': 38, 'i': 39, 'j': 40, 'k': 41, 'l': 42, 'm': 43, 'n': 44, 'o': 45, 'p': 46, 'q': 47, 'r': 48, 's': 49, 't': 50, 'u': 51, 'v': 52, 'w': 53, 'x': 54, 'y': 55, 'z': 56}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8_q3Mp0uUmO"
      },
      "source": [
        "##### 인덱스 0부터 28까지는 공백을 포함한 각종 구두점, 특수문자가 존재하고, 인덱스 29부터 54까지는 a부터 z까지 총 26개의 알파벳 소문자가 글자 집합에 포함되어져 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKAUTcNyuPCf"
      },
      "source": [
        "# 인덱스로부터 글자를 리턴하는 index_to_char 만들기\n",
        "index_to_char={}\n",
        "for key, value in char_to_index.items():\n",
        "    index_to_char[value] = key"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dm9kDoTu19d",
        "outputId": "6cabad17-3a40-4a6a-c051-e1500a4cb09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seq_length = 60 # 문장의 길이를 60으로 한다.\n",
        "n_samples = int(np.floor((len(text) - 1) / seq_length)) # 문자열을 60등분한다. 그러면 즉, 총 샘플의 개수\n",
        "print ('문장 샘플의 수 : {}'.format(n_samples))\n",
        "# 문장 샘플의 수 : 2663"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수 : 2663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynSidcbau6T0",
        "outputId": "98f63ed7-e52f-41e7-942a-9f05f53f9203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "train_X = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples): # 2,646번 수행\n",
        "    X_sample = text[i * seq_length: (i + 1) * seq_length]\n",
        "    # 0:60 -> 60:120 -> 120:180로 loop를 돌면서 문장 샘플을 1개씩 가져온다.\n",
        "    X_encoded = [char_to_index[c] for c in X_sample] # 하나의 문장 샘플에 대해서 정수 인코딩\n",
        "    train_X.append(X_encoded)\n",
        "\n",
        "    y_sample = text[i * seq_length + 1: (i + 1) * seq_length + 1] # 오른쪽으로 1칸 쉬프트한다.\n",
        "    y_encoded = [char_to_index[c] for c in y_sample]\n",
        "    train_y.append(y_encoded)\n",
        "\n",
        "print(train_X[0])\n",
        "print(train_y[0])\n",
        "print(train_X[1])\n",
        "print(train_y[1])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[50, 38, 35, 0, 46, 48, 45, 40, 35, 33, 50, 0, 37, 51, 50, 35, 44, 32, 35, 48, 37, 0, 35, 32, 45, 45, 41, 0, 45, 36, 0, 31, 42, 39, 33, 35, 49, 0, 31, 34, 52, 35, 44, 50, 51, 48, 35, 49, 0, 39, 44, 0, 53, 45, 44, 34, 35, 48, 42, 31]\n",
            "[38, 35, 0, 46, 48, 45, 40, 35, 33, 50, 0, 37, 51, 50, 35, 44, 32, 35, 48, 37, 0, 35, 32, 45, 45, 41, 0, 45, 36, 0, 31, 42, 39, 33, 35, 49, 0, 31, 34, 52, 35, 44, 50, 51, 48, 35, 49, 0, 39, 44, 0, 53, 45, 44, 34, 35, 48, 42, 31, 44]\n",
            "[44, 34, 10, 0, 32, 55, 0, 42, 35, 53, 39, 49, 0, 33, 31, 48, 48, 45, 42, 42, 0, 50, 38, 39, 49, 0, 35, 32, 45, 45, 41, 0, 39, 49, 0, 36, 45, 48, 0, 50, 38, 35, 0, 51, 49, 35, 0, 45, 36, 0, 31, 44, 55, 45, 44, 35, 0, 31, 44, 55]\n",
            "[34, 10, 0, 32, 55, 0, 42, 35, 53, 39, 49, 0, 33, 31, 48, 48, 45, 42, 42, 0, 50, 38, 39, 49, 0, 35, 32, 45, 45, 41, 0, 39, 49, 0, 36, 45, 48, 0, 50, 38, 35, 0, 51, 49, 35, 0, 45, 36, 0, 31, 44, 55, 45, 44, 35, 0, 31, 44, 55, 53]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kadHHIpBvpRZ"
      },
      "source": [
        "##### train_y[1]은 train_X[1]에서 오른쪽으로 한 칸 쉬프트 된 문장임을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ggQNvmvQLq",
        "outputId": "b776f797-10dc-44fa-f76d-cba99b57e652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# train_X와 train_y에 대해서 원-핫 인코딩을 수행\n",
        "# 임베딩층을 사용하지 않을 것이므로 입력 시퀀스인 train_X에 대해서도 원-핫 인코딩을 한다.\n",
        "\n",
        "train_X = to_categorical(train_X)\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
        "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_X의 크기(shape) : (2663, 60, 57)\n",
            "train_y의 크기(shape) : (2663, 60, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCCNAV02wu6s"
      },
      "source": [
        "![rnn_image6between7.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0gIKFKuw5qe"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lu4IEbVwDhc",
        "outputId": "da0945d7-bce2-4c44-ae8c-33483b6b0415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_X, train_y, epochs=80, verbose=2)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 - 39s - loss: 3.0740 - accuracy: 0.1816\n",
            "Epoch 2/80\n",
            "84/84 - 39s - loss: 2.7133 - accuracy: 0.2507\n",
            "Epoch 3/80\n",
            "84/84 - 38s - loss: 2.3843 - accuracy: 0.3293\n",
            "Epoch 4/80\n",
            "84/84 - 39s - loss: 2.2478 - accuracy: 0.3627\n",
            "Epoch 5/80\n",
            "84/84 - 40s - loss: 2.1503 - accuracy: 0.3861\n",
            "Epoch 6/80\n",
            "84/84 - 39s - loss: 2.0634 - accuracy: 0.4051\n",
            "Epoch 7/80\n",
            "84/84 - 39s - loss: 1.9914 - accuracy: 0.4245\n",
            "Epoch 8/80\n",
            "84/84 - 39s - loss: 1.9304 - accuracy: 0.4413\n",
            "Epoch 9/80\n",
            "84/84 - 38s - loss: 1.8748 - accuracy: 0.4559\n",
            "Epoch 10/80\n",
            "84/84 - 39s - loss: 1.8275 - accuracy: 0.4690\n",
            "Epoch 11/80\n",
            "84/84 - 40s - loss: 1.7821 - accuracy: 0.4827\n",
            "Epoch 12/80\n",
            "84/84 - 42s - loss: 1.7404 - accuracy: 0.4935\n",
            "Epoch 13/80\n",
            "84/84 - 41s - loss: 1.7039 - accuracy: 0.5035\n",
            "Epoch 14/80\n",
            "84/84 - 39s - loss: 1.6685 - accuracy: 0.5128\n",
            "Epoch 15/80\n",
            "84/84 - 39s - loss: 1.6350 - accuracy: 0.5218\n",
            "Epoch 16/80\n",
            "84/84 - 39s - loss: 1.6024 - accuracy: 0.5294\n",
            "Epoch 17/80\n",
            "84/84 - 39s - loss: 1.5715 - accuracy: 0.5363\n",
            "Epoch 18/80\n",
            "84/84 - 39s - loss: 1.5425 - accuracy: 0.5449\n",
            "Epoch 19/80\n",
            "84/84 - 40s - loss: 1.5126 - accuracy: 0.5521\n",
            "Epoch 20/80\n",
            "84/84 - 39s - loss: 1.4822 - accuracy: 0.5598\n",
            "Epoch 21/80\n",
            "84/84 - 40s - loss: 1.4563 - accuracy: 0.5673\n",
            "Epoch 22/80\n",
            "84/84 - 39s - loss: 1.4265 - accuracy: 0.5761\n",
            "Epoch 23/80\n",
            "84/84 - 39s - loss: 1.3990 - accuracy: 0.5838\n",
            "Epoch 24/80\n",
            "84/84 - 39s - loss: 1.3695 - accuracy: 0.5928\n",
            "Epoch 25/80\n",
            "84/84 - 39s - loss: 1.3430 - accuracy: 0.5998\n",
            "Epoch 26/80\n",
            "84/84 - 39s - loss: 1.3147 - accuracy: 0.6073\n",
            "Epoch 27/80\n",
            "84/84 - 40s - loss: 1.2875 - accuracy: 0.6154\n",
            "Epoch 28/80\n",
            "84/84 - 40s - loss: 1.2605 - accuracy: 0.6230\n",
            "Epoch 29/80\n",
            "84/84 - 40s - loss: 1.2321 - accuracy: 0.6312\n",
            "Epoch 30/80\n",
            "84/84 - 39s - loss: 1.2042 - accuracy: 0.6399\n",
            "Epoch 31/80\n",
            "84/84 - 39s - loss: 1.1755 - accuracy: 0.6484\n",
            "Epoch 32/80\n",
            "84/84 - 39s - loss: 1.1478 - accuracy: 0.6568\n",
            "Epoch 33/80\n",
            "84/84 - 39s - loss: 1.1190 - accuracy: 0.6652\n",
            "Epoch 34/80\n",
            "84/84 - 39s - loss: 1.0914 - accuracy: 0.6727\n",
            "Epoch 35/80\n",
            "84/84 - 39s - loss: 1.0624 - accuracy: 0.6816\n",
            "Epoch 36/80\n",
            "84/84 - 39s - loss: 1.0331 - accuracy: 0.6920\n",
            "Epoch 37/80\n",
            "84/84 - 39s - loss: 1.0049 - accuracy: 0.7007\n",
            "Epoch 38/80\n",
            "84/84 - 39s - loss: 0.9753 - accuracy: 0.7095\n",
            "Epoch 39/80\n",
            "84/84 - 39s - loss: 0.9477 - accuracy: 0.7181\n",
            "Epoch 40/80\n",
            "84/84 - 38s - loss: 0.9192 - accuracy: 0.7263\n",
            "Epoch 41/80\n",
            "84/84 - 39s - loss: 0.8942 - accuracy: 0.7347\n",
            "Epoch 42/80\n",
            "84/84 - 39s - loss: 0.8642 - accuracy: 0.7440\n",
            "Epoch 43/80\n",
            "84/84 - 38s - loss: 0.8368 - accuracy: 0.7519\n",
            "Epoch 44/80\n",
            "84/84 - 44s - loss: 0.8099 - accuracy: 0.7613\n",
            "Epoch 45/80\n",
            "84/84 - 40s - loss: 0.7832 - accuracy: 0.7699\n",
            "Epoch 46/80\n",
            "84/84 - 39s - loss: 0.7559 - accuracy: 0.7787\n",
            "Epoch 47/80\n",
            "84/84 - 40s - loss: 0.7304 - accuracy: 0.7862\n",
            "Epoch 48/80\n",
            "84/84 - 39s - loss: 0.7037 - accuracy: 0.7949\n",
            "Epoch 49/80\n",
            "84/84 - 39s - loss: 0.6789 - accuracy: 0.8028\n",
            "Epoch 50/80\n",
            "84/84 - 40s - loss: 0.6559 - accuracy: 0.8098\n",
            "Epoch 51/80\n",
            "84/84 - 38s - loss: 0.6278 - accuracy: 0.8197\n",
            "Epoch 52/80\n",
            "84/84 - 39s - loss: 0.6097 - accuracy: 0.8248\n",
            "Epoch 53/80\n",
            "84/84 - 39s - loss: 0.5876 - accuracy: 0.8325\n",
            "Epoch 54/80\n",
            "84/84 - 39s - loss: 0.5636 - accuracy: 0.8401\n",
            "Epoch 55/80\n",
            "84/84 - 39s - loss: 0.5418 - accuracy: 0.8469\n",
            "Epoch 56/80\n",
            "84/84 - 39s - loss: 0.5175 - accuracy: 0.8554\n",
            "Epoch 57/80\n",
            "84/84 - 38s - loss: 0.4984 - accuracy: 0.8615\n",
            "Epoch 58/80\n",
            "84/84 - 39s - loss: 0.4796 - accuracy: 0.8670\n",
            "Epoch 59/80\n",
            "84/84 - 39s - loss: 0.4614 - accuracy: 0.8737\n",
            "Epoch 60/80\n",
            "84/84 - 44s - loss: 0.4424 - accuracy: 0.8794\n",
            "Epoch 61/80\n",
            "84/84 - 40s - loss: 0.4218 - accuracy: 0.8863\n",
            "Epoch 62/80\n",
            "84/84 - 39s - loss: 0.4089 - accuracy: 0.8897\n",
            "Epoch 63/80\n",
            "84/84 - 38s - loss: 0.3916 - accuracy: 0.8965\n",
            "Epoch 64/80\n",
            "84/84 - 41s - loss: 0.3699 - accuracy: 0.9033\n",
            "Epoch 65/80\n",
            "84/84 - 43s - loss: 0.3541 - accuracy: 0.9086\n",
            "Epoch 66/80\n",
            "84/84 - 42s - loss: 0.3381 - accuracy: 0.9136\n",
            "Epoch 67/80\n",
            "84/84 - 41s - loss: 0.3321 - accuracy: 0.9148\n",
            "Epoch 68/80\n",
            "84/84 - 40s - loss: 0.3197 - accuracy: 0.9186\n",
            "Epoch 69/80\n",
            "84/84 - 38s - loss: 0.3022 - accuracy: 0.9241\n",
            "Epoch 70/80\n",
            "84/84 - 41s - loss: 0.2851 - accuracy: 0.9305\n",
            "Epoch 71/80\n",
            "84/84 - 42s - loss: 0.2776 - accuracy: 0.9316\n",
            "Epoch 72/80\n",
            "84/84 - 42s - loss: 0.2712 - accuracy: 0.9334\n",
            "Epoch 73/80\n",
            "84/84 - 43s - loss: 0.2598 - accuracy: 0.9365\n",
            "Epoch 74/80\n",
            "84/84 - 47s - loss: 0.2499 - accuracy: 0.9397\n",
            "Epoch 75/80\n",
            "84/84 - 43s - loss: 0.2391 - accuracy: 0.9425\n",
            "Epoch 76/80\n",
            "84/84 - 43s - loss: 0.2260 - accuracy: 0.9467\n",
            "Epoch 77/80\n",
            "84/84 - 42s - loss: 0.2189 - accuracy: 0.9479\n",
            "Epoch 78/80\n",
            "84/84 - 41s - loss: 0.2160 - accuracy: 0.9480\n",
            "Epoch 79/80\n",
            "84/84 - 41s - loss: 0.2181 - accuracy: 0.9462\n",
            "Epoch 80/80\n",
            "84/84 - 41s - loss: 0.2165 - accuracy: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb71ff086a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvkUd2uIxCbE",
        "outputId": "ea128acd-a11d-4d76-ef5e-fbf9614868f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]] # 랜덤 익덱스로부터 글자 생성\n",
        "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
        "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)\n",
        "sentence_generation(model, 100)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 번 글자 # 로 예측을 시작!\n",
            "#"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-638583d2091a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msentence_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-638583d2091a>\u001b[0m in \u001b[0;36msentence_generation\u001b[0;34m(model, length)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0my_char\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [?,57] from a tensor with shape [1,33]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_5/lstm_1/PartitionedCall]] [Op:__inference_predict_function_134170]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ChgByUxLja"
      },
      "source": [
        "# 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qXp2LZqxZRb"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCe2z2dlxHG5",
        "outputId": "d465b7ff-559d-4eca-b9de-a63c4aea46dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "to_categorical = tf.keras.utils.to_categorical\n",
        "\n",
        "text='''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''\n",
        "\n",
        "# 위의 텍스트에 존재하는 단락 구분을 없애고 하나의 문자열로 재저장\n",
        "tokens = text.split() # '\\n 제거'\n",
        "text = ' '.join(tokens)\n",
        "print(text)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-C1Fh-DyFYp"
      },
      "source": [
        "##### 단락이 없어지고 하나의 문자열로 재저장됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlDhCRPWxybz",
        "outputId": "6aa03313-706c-40e0-d48d-a70b3061cf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 글자 집합 만들기\n",
        "char_vocab = sorted(list(set(text))) # 중복을 제거한 글자 집합 생성\n",
        "print(char_vocab)\n",
        "# 알파벳 또는 구두점 등의 단위의 집합인 글자 집합 생성됨\n",
        "\n",
        "vocab_size=len(char_vocab)\n",
        "print ('글자 집합의 크기 : {}'.format(vocab_size))\n",
        "# 글자 집합의 크기 : 33\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab)) # 글자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
            "글자 집합의 크기 : 33\n",
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W86Ygrw-3ZeB"
      },
      "source": [
        "# 훈련에 사용할 문장 샘플 만들기\n",
        "# Example) 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측. 즉, RNN의 time step은 5번\n",
        "##### stude -> n \n",
        "##### tuden -> t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkWBZJ_AyRby",
        "outputId": "b56642cf-fe4f-42c1-fb44-925f80433905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# 훈련에 사용할 문장 샘플 만들기\n",
        "# Example) 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측. 즉, RNN의 time step은 5번\n",
        "stude -> n \n",
        "tuden -> t"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-dedac4117f1e>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    stude -> n\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVaoM40Izl_r"
      },
      "source": [
        "# 입력 시퀀스의 길이, 모든 샘플들의 길이가 10이 되도록 데이터를 구성\n",
        "# 예측 대상이 되는 글자도 필요하므로 우선 길이가 11이 되도록 데이터를 구성\n",
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(text)):\n",
        "    seq = text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
        "    sequences.append(seq)\n",
        "print('총 훈련 샘플의 수: %d' % len(sequences))\n",
        "# 총 훈련 샘플의 수 :\n",
        "\n",
        "sequences[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-4bQFiIz-tY"
      },
      "source": [
        "# char_to_index를 사용하여 전체 데이터에 대해서 정수 인코딩을 수행\n",
        "\n",
        "X = []\n",
        "for line in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
        "    temp_X = [char_to_index[char] for char in line] # 문장 샘플에서 각 글자에 대해서 정수 인코딩을 수행.\n",
        "    X.append(temp_X)\n",
        "\n",
        "for line in X[:5]:\n",
        "    print(line)\n",
        "\n",
        "# 글자 분리시켜주는 작업\n",
        "sequences = np.array(x)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1] # 맨 마지막 위치의 글자를 분리\n",
        "\n",
        "for line in X[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUoY6D_0Lv3"
      },
      "source": [
        "# X와 y에 대해서 원-핫 인코딩 수행\n",
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in X] # X에 대한 원-핫 인코딩\n",
        "X = np.array(sequences)\n",
        "y = to_categorical(y, num_classes=vocab_size) # y에 대한 원-핫 인코딩\n",
        "\n",
        "print(X.shape)\n",
        "# 현재 X의 크기는 426 * 10 * 33"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDtDSsiS0o74"
      },
      "source": [
        "![rnn_image6between7-2.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HOFsRph0zRx"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoNcAJhF0n8R"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(80, input_shape=(X.shape[1], X.shape[2]))) # X.shape[1]은 25, X.shape[2]는 33\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP_gjRYv1EGM"
      },
      "source": [
        "##### LSTM을 사용하고, 은닉 상태의 크기는 80, 그리고 출력층에 단어 집합의 크기만큼의 뉴런을 배치하여 모델을 설계\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw4jBVQ06XF"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, verbose=2)\n",
        "# 출력층의 활성화 함수로는 소프트맥스 함수, 손실 함수로는 크로스 엔트로피 함수를 사용\n",
        "\n",
        "# 문장을 생성하는 함수 sentence_generation를 만들어서 문장을 생성\n",
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "# 모델, 인덱스 정보, 문장 길이, 초기 시퀀스, 반복 횟수\n",
        "    init_text = seed_text # 문장 생성에 사용할 초기 시퀀스\n",
        "    sentence = ''\n",
        "\n",
        "    for _ in range(n): # n번 반복\n",
        "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
        "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "        result = model.predict_classes(encoded, verbose=0)\n",
        "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 글자)를 result에 저장.\n",
        "        for char, index in char_to_index.items(): # 만약 예측한 글자와 인덱스와 동일한 글자가 있다면\n",
        "            if index == result: # 해당 글자가 예측 글자이므로 break\n",
        "                break\n",
        "        seed_text=seed_text + char # 현재 시퀀스 + 예측 글자를 현재 시퀀스로 변경\n",
        "        sentence=sentence + char # 예측 글자를 문장에 저장\n",
        "        # for문이므로 이 작업을 다시 반복\n",
        "\n",
        "    sentence = init_text + sentence\n",
        "    return sentence\n",
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}