{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "양방향 LSTM을 이용한 품사 태깅.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIS-SG/ai_lab_224n_NLP/blob/main/%EC%96%91%EB%B0%A9%ED%96%A5_LSTM%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%92%88%EC%82%AC_%ED%83%9C%EA%B9%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUyLpIePfzka"
      },
      "source": [
        "# 딥러닝을 이용한 자연어 처리 입문 - 메모리 네트워크\n",
        "##### 참고자료 : https://wikidocs.net/82475"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLz82YEpaCuJ"
      },
      "source": [
        "## 메모리 네트워크 구조\n",
        "### Babi 데이터셋 전처리하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X75Tt0QDJ9M"
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from nltk import FreqDist\n",
        "from functools import reduce\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XorkIKfarENZ",
        "outputId": "3dfdb5b0-bf91-43f4-b862-d00d217fde18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                'babi_tasks_1-20_v1-2.tar.gz')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL2HEA7ZZxIo"
      },
      "source": [
        "with tarfile.open(path) as tar:\n",
        " tar.extractall()\n",
        " tar.close()\n",
        "\n",
        "DATA_DIR = 'tasks_1-20_v1-2/en-10k'\n",
        "TRAIN_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_train.txt\")\n",
        "TEST_FILE = os.path.join(DATA_DIR, \"qa1_single-supporting-fact_test.txt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymWA8L06Z0at",
        "outputId": "13113f51-8582-4e13-c89d-cb838e0f9b6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i = 0\n",
        "lines = open(TRAIN_FILE , \"rb\")\n",
        "for line in lines:\n",
        "    line = line.decode(\"utf-8\").strip()\n",
        "    # lno, text = line.split(\" \", 1) # ID와 TEXT 분리\n",
        "    i = i + 1\n",
        "    print(line)\n",
        "    if i == 20:\n",
        "      break"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Mary moved to the bathroom.\n",
            "2 John went to the hallway.\n",
            "3 Where is Mary? \tbathroom\t1\n",
            "4 Daniel went back to the hallway.\n",
            "5 Sandra moved to the garden.\n",
            "6 Where is Daniel? \thallway\t4\n",
            "7 John moved to the office.\n",
            "8 Sandra journeyed to the bathroom.\n",
            "9 Where is Daniel? \thallway\t4\n",
            "10 Mary moved to the hallway.\n",
            "11 Daniel travelled to the office.\n",
            "12 Where is Daniel? \toffice\t11\n",
            "13 John went back to the garden.\n",
            "14 John moved to the bedroom.\n",
            "15 Where is Sandra? \tbathroom\t8\n",
            "1 Sandra travelled to the office.\n",
            "2 Sandra went to the bathroom.\n",
            "3 Where is Sandra? \tbathroom\t2\n",
            "4 Mary went to the bedroom.\n",
            "5 Daniel moved to the hallway.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ3o7b8VZ3-b"
      },
      "source": [
        "def read_data(dir):\n",
        "    stories, questions, answers = [], [], [] # 각각 스토리, 질문, 답변을 저장할 예정\n",
        "    story_temp = [] # 현재 시점의 스토리 임시 저장\n",
        "    lines = open(dir, \"rb\")\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.decode(\"utf-8\") # b' 제거\n",
        "        line = line.strip() # '\\n' 제거\n",
        "        idx, text = line.split(\" \", 1) # 맨 앞에 있는 id number 분리\n",
        "        # 여기까지는 모든 줄에 적용되는 전처리\n",
        "\n",
        "        if int(idx) == 1:\n",
        "            story_temp = []\n",
        "\n",
        "        if \"\\t\" in text: # 현재 읽는 줄이 질문 (tab) 답변 (tab)인 경우\n",
        "            question, answer, _ = text.split(\"\\t\") # 질문과 답변을 각각 저장\n",
        "            stories.append([x for x in story_temp if x]) # 지금까지의 누적 스토리를 스토리에 저장\n",
        "            questions.append(question)\n",
        "            answers.append(answer)\n",
        "\n",
        "        else: # 현재 읽는 줄이 스토리인 경우\n",
        "            story_temp.append(text) # 임시 저장\n",
        "\n",
        "    lines.close()\n",
        "    return stories, questions, answers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tI-dzNwZ6ge"
      },
      "source": [
        "train_data = read_data(TRAIN_FILE)\n",
        "test_data = read_data(TEST_FILE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRdatNEUrgXL"
      },
      "source": [
        "train_stories, train_questions, train_answers = read_data(TRAIN_FILE)\n",
        "test_stories, test_questions, test_answers = read_data(TEST_FILE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxjruTJ_rh5z",
        "outputId": "9221bf9f-8f1f-4978-ba78-698ef6c85010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('훈련용 스토리의 개수 :', len(train_stories))\n",
        "print('훈련용 질문의 개수 :',len(train_questions))\n",
        "print('훈련용 답변의 개수 :',len(train_answers))\n",
        "print('테스트용 스토리의 개수 :',len(test_stories))\n",
        "print('테스트용 질문의 개수 :',len(test_questions))\n",
        "print('테스트용 답변의 개수 :',len(test_answers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 스토리의 개수 : 10000\n",
            "훈련용 질문의 개수 : 10000\n",
            "훈련용 답변의 개수 : 10000\n",
            "테스트용 스토리의 개수 : 1000\n",
            "테스트용 질문의 개수 : 1000\n",
            "테스트용 답변의 개수 : 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwsxb6UVroPo",
        "outputId": "32e91eb1-8d10-4625-d6d6-22ac646ac543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_stories[3576]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John went back to the garden.',\n",
              " 'Mary went to the kitchen.',\n",
              " 'Sandra went back to the bedroom.',\n",
              " 'John travelled to the bedroom.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0naPhmmr2gc",
        "outputId": "db859395-2add-4a9b-fd0a-e09e550c92e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "train_questions[3576]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Where is John? '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeUkTwqir_g8",
        "outputId": "f510cba1-44e1-4ba9-971a-a4c799701f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "train_answers[3576]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bedroom'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWAYrv9asDiJ"
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpJCwT0UsHod"
      },
      "source": [
        "def preprocess_data(train_data, test_data):\n",
        "    counter = FreqDist()\n",
        "\n",
        "    # 두 문장의 story를 하나의 문장으로 통합하는 함수\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    # 각 샘플의 길이를 저장하는 리스트\n",
        "    story_len = []\n",
        "    question_len = []\n",
        "\n",
        "    for stories, questions, answers in [train_data, test_data]:\n",
        "        for story in stories:\n",
        "            stories = tokenize(flatten(story)) # 스토리의 문장들을 펼친 후 토큰화\n",
        "            story_len.append(len(stories)) # 각 story의 길이 저장\n",
        "            for word in stories: # 단어 집합에 단어 추가\n",
        "                counter[word] += 1\n",
        "        for question in questions:\n",
        "            question = tokenize(question)\n",
        "            question_len.append(len(question))\n",
        "            for word in question:\n",
        "                counter[word] += 1\n",
        "        for answer in answers:\n",
        "            answer = tokenize(answer)\n",
        "            for word in answer:\n",
        "                counter[word] += 1\n",
        "\n",
        "    # 단어 집합 생성\n",
        "    word2idx = {word : (idx + 1) for idx, (word, _) in enumerate(counter.most_common())}\n",
        "    idx2word = {idx : word for word, idx in word2idx.items()}\n",
        "\n",
        "    # 가장 긴 샘플의 길이\n",
        "    story_max_len = np.max(story_len)\n",
        "    question_max_len = np.max(question_len)\n",
        "\n",
        "    return word2idx, idx2word, story_max_len, question_max_len"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVhy-24-sOxI",
        "outputId": "dd17604f-d063-427b-9a1c-ccb3bc107490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2idx, idx2word, story_max_len, question_max_len = preprocess_data(train_data, test_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dun5I7KZ8UN",
        "outputId": "d1eb48f9-b92c-4e71-e55c-27813825f7f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(word2idx)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'to': 1, 'the': 2, '.': 3, 'went': 4, 'Sandra': 5, 'John': 6, 'Daniel': 7, 'Mary': 8, 'travelled': 9, 'journeyed': 10, 'back': 11, 'bathroom': 12, 'garden': 13, 'hallway': 14, 'moved': 15, 'office': 16, 'kitchen': 17, 'bedroom': 18, 'Where': 19, 'is': 20, '?': 21}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEWUGOXVaIWD"
      },
      "source": [
        "vocab_size = len(word2idx) + 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpOpPXKvaJvJ",
        "outputId": "645476a2-4dea-473f-860b-d0ffc8ae50ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('스토리의 최대 길이 :',story_max_len)\n",
        "print('질문의 최대 길이 :',question_max_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "스토리의 최대 길이 : 68\n",
            "질문의 최대 길이 : 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKJcUKa2aLqq"
      },
      "source": [
        "def vectorize(data, word2idx, story_maxlen, question_maxlen):\n",
        "    Xs, Xq, Y = [], [], []\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "\n",
        "    stories, questions, answers = data\n",
        "    for story, question, answer in zip(stories, questions, answers):\n",
        "        xs = [word2idx[w] for w in tokenize(flatten(story))]\n",
        "        xq = [word2idx[w] for w in tokenize(question)]\n",
        "        Xs.append(xs)\n",
        "        Xq.append(xq)\n",
        "        Y.append(word2idx[answer])\n",
        "\n",
        "        # 스토리와 질문은 각각의 최대 길이로 패딩\n",
        "        # 정답은 원-핫 인코딩\n",
        "    return pad_sequences(Xs, maxlen=story_maxlen),\\\n",
        "           pad_sequences(Xq, maxlen=question_maxlen),\\\n",
        "           to_categorical(Y, num_classes=len(word2idx) + 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8cTEJCxaNCs",
        "outputId": "c3c1b271-607d-40bb-ae92-6c456987e794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Xstrain, Xqtrain, Ytrain = vectorize(train_data, word2idx, story_max_len, question_max_len)\n",
        "Xstest, Xqtest, Ytest = vectorize(test_data, word2idx, story_max_len, question_max_len)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIbeRYV33_Wg",
        "outputId": "2ccd67c4-86d1-4e77-c847-4241e138f3d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(Xstrain.shape, Xqtrain.shape, Ytrain.shape, Xstest.shape, Xqtest.shape, Ytest.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 68) (10000, 4) (10000, 22) (1000, 68) (1000, 4) (1000, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnQexuw_4C-A"
      },
      "source": [
        "## 메모리 네트워크로 QA 태스크 풀기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK_DQTNI4BMh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Permute, dot, add, concatenate\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Activation"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDQD37pz4HuQ"
      },
      "source": [
        "train_epochs = 120\n",
        "# 배치 크기\n",
        "batch_size = 32\n",
        "# 임베딩 크기\n",
        "embed_size = 50\n",
        "# LSTM의 크기\n",
        "lstm_size = 64\n",
        "# 과적합 방지 기법인 드롭아웃 적용 비율\n",
        "dropout_rate = 0.30"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuaTl_qN4JYX",
        "outputId": "564d2a54-47f0-4079-808c-3d7b7a82a4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 플레이스 홀더. 입력을 담는 변수\n",
        "input_sequence = Input((story_max_len,))\n",
        "question = Input((question_max_len,))\n",
        "\n",
        "print('Stories :', input_sequence)\n",
        "print('Question:', question)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stories : Tensor(\"input_1:0\", shape=(None, 68), dtype=float32)\n",
            "Question: Tensor(\"input_2:0\", shape=(None, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKybIeq84LAh"
      },
      "source": [
        "# 스토리를 위한 첫번째 임베딩. 그림에서의 Embedding A\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=embed_size))\n",
        "input_encoder_m.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, embedding_dim) / 샘플의 수, 문장의 최대 길이, 임베딩 벡터의 차원\n",
        "\n",
        "# 스토리를 위한 두번째 임베딩. 그림에서의 Embedding C\n",
        "# 임베딩 벡터의 차원을 question_max_len(질문의 최대 길이)로 한다.\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=question_max_len))\n",
        "input_encoder_c.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, story_max_len, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이(임베딩 벡터의 차원)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmwdxxXz4OtH"
      },
      "source": [
        "# 질문을 위한 임베딩. 그림에서의 Embedding B\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embed_size,\n",
        "                               input_length=question_max_len))\n",
        "question_encoder.add(Dropout(dropout_rate))\n",
        "# 결과 : (samples, question_max_len, embedding_dim) / 샘플의 수, 질문의 최대 길이, 임베딩 벡터의 차원"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-3mYdR4QnO",
        "outputId": "6f2dfec2-f8ef-4fba-b01e-905356dbcadd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 실질적인 임베딩 과정\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "print('Input encoded m', input_encoded_m)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "print('Question encoded', question_encoded)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input encoded m Tensor(\"sequential/dropout/cond/Identity:0\", shape=(None, 68, 50), dtype=float32)\n",
            "Input encoded c Tensor(\"sequential_1/dropout_1/cond/Identity:0\", shape=(None, 68, 4), dtype=float32)\n",
            "Question encoded Tensor(\"sequential_2/dropout_2/cond/Identity:0\", shape=(None, 4, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJv_C9nV4SvO",
        "outputId": "824dc157-97f8-4278-a88d-8aae41309ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 스토리 단어들과 질문 단어들 간의 유사도를 구하는 과정\n",
        "# 유사도는 내적을 사용한다.\n",
        "match = dot([input_encoded_m, question_encoded], axes=-1, normalize=False)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "# 결과 : (samples, story_maxlen, question_max_len) / 샘플의 수, 문장의 최대 길이, 질문의 최대 길이\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_max_len, question_max_len)\n",
        "response = Permute((2, 1))(response)  # (samples, question_max_len, story_max_len)\n",
        "print('Response shape', response)\n",
        "\n",
        "# concatenate the response vector with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n",
        "\n",
        "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
        "answer = Dropout(dropout_rate)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match shape Tensor(\"activation/truediv:0\", shape=(None, 68, 4), dtype=float32)\n",
            "Response shape Tensor(\"permute/transpose:0\", shape=(None, 4, 68), dtype=float32)\n",
            "Answer shape Tensor(\"concatenate/concat:0\", shape=(None, 4, 118), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgrRfsNW4VPW",
        "outputId": "dfbdeb16-e5ff-4098-d7a1-42a6dbedfcf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "# start training the model\n",
        "history = model.fit([Xstrain, Xqtrain],\n",
        "         Ytrain, batch_size, train_epochs,\n",
        "         validation_data=([Xstest, Xqtest], Ytest))\n",
        "\n",
        "# save model\n",
        "model.save('model.h5')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 50)     1100        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 4, 50)        1100        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 68, 4)        0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 68, 4)        0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 4)      88          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 68, 4)        0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 4, 68)        0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4, 118)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 64)           46848       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 64)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 22)           1430        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 22)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 50,566\n",
            "Trainable params: 50,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/120\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.8745 - acc: 0.1774 - val_loss: 1.7695 - val_acc: 0.1820\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.6732 - acc: 0.2705 - val_loss: 1.5871 - val_acc: 0.3780\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.5328 - acc: 0.3801 - val_loss: 1.5052 - val_acc: 0.3930\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.4830 - acc: 0.4034 - val_loss: 1.4734 - val_acc: 0.4250\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.4482 - acc: 0.4289 - val_loss: 1.4173 - val_acc: 0.4560\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.3973 - acc: 0.4570 - val_loss: 1.3548 - val_acc: 0.4950\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.3568 - acc: 0.4797 - val_loss: 1.3487 - val_acc: 0.4880\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3339 - acc: 0.4886 - val_loss: 1.3137 - val_acc: 0.5010\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.3134 - acc: 0.4960 - val_loss: 1.3048 - val_acc: 0.5040\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2867 - acc: 0.5056 - val_loss: 1.2818 - val_acc: 0.5060\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2645 - acc: 0.5076 - val_loss: 1.2779 - val_acc: 0.4950\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2383 - acc: 0.5158 - val_loss: 1.2253 - val_acc: 0.5160\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2130 - acc: 0.5164 - val_loss: 1.1945 - val_acc: 0.5330\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2058 - acc: 0.5160 - val_loss: 1.2135 - val_acc: 0.5220\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1943 - acc: 0.5187 - val_loss: 1.2034 - val_acc: 0.5220\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1850 - acc: 0.5163 - val_loss: 1.1737 - val_acc: 0.5290\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1643 - acc: 0.5261 - val_loss: 1.1790 - val_acc: 0.5150\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1608 - acc: 0.5206 - val_loss: 1.1730 - val_acc: 0.5190\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1523 - acc: 0.5306 - val_loss: 1.1571 - val_acc: 0.5180\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1453 - acc: 0.5302 - val_loss: 1.1642 - val_acc: 0.5190\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1393 - acc: 0.5271 - val_loss: 1.1572 - val_acc: 0.5120\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1306 - acc: 0.5269 - val_loss: 1.1864 - val_acc: 0.4950\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1144 - acc: 0.5329 - val_loss: 1.1562 - val_acc: 0.5220\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1131 - acc: 0.5283 - val_loss: 1.2005 - val_acc: 0.5210\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1136 - acc: 0.5317 - val_loss: 1.1629 - val_acc: 0.5230\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1069 - acc: 0.5357 - val_loss: 1.1581 - val_acc: 0.5100\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0997 - acc: 0.5306 - val_loss: 1.1727 - val_acc: 0.5210\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0918 - acc: 0.5358 - val_loss: 1.1644 - val_acc: 0.5160\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0881 - acc: 0.5400 - val_loss: 1.1584 - val_acc: 0.5150\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0842 - acc: 0.5426 - val_loss: 1.1497 - val_acc: 0.5150\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0755 - acc: 0.5429 - val_loss: 1.1819 - val_acc: 0.5160\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0715 - acc: 0.5500 - val_loss: 1.1552 - val_acc: 0.5150\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0635 - acc: 0.5477 - val_loss: 1.1625 - val_acc: 0.5130\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0588 - acc: 0.5523 - val_loss: 1.1664 - val_acc: 0.5130\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0488 - acc: 0.5542 - val_loss: 1.1491 - val_acc: 0.4980\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0389 - acc: 0.5539 - val_loss: 1.1542 - val_acc: 0.5040\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0329 - acc: 0.5615 - val_loss: 1.1675 - val_acc: 0.5070\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0348 - acc: 0.5545 - val_loss: 1.1739 - val_acc: 0.5160\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0245 - acc: 0.5646 - val_loss: 1.1551 - val_acc: 0.4920\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0219 - acc: 0.5602 - val_loss: 1.1719 - val_acc: 0.5170\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0061 - acc: 0.5726 - val_loss: 1.1914 - val_acc: 0.5020\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.0088 - acc: 0.5735 - val_loss: 1.1658 - val_acc: 0.5140\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.9985 - acc: 0.5795 - val_loss: 1.1720 - val_acc: 0.5110\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.9768 - acc: 0.5877 - val_loss: 1.1712 - val_acc: 0.5060\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.9734 - acc: 0.5869 - val_loss: 1.1673 - val_acc: 0.5100\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9546 - acc: 0.5983 - val_loss: 1.1521 - val_acc: 0.5310\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9344 - acc: 0.6076 - val_loss: 1.1284 - val_acc: 0.5440\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.9139 - acc: 0.6326 - val_loss: 1.1092 - val_acc: 0.5590\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8950 - acc: 0.6437 - val_loss: 1.1126 - val_acc: 0.5750\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8541 - acc: 0.6641 - val_loss: 1.0539 - val_acc: 0.6070\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8158 - acc: 0.6905 - val_loss: 0.9974 - val_acc: 0.6260\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.7758 - acc: 0.7057 - val_loss: 0.9778 - val_acc: 0.6380\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.7492 - acc: 0.7228 - val_loss: 0.9188 - val_acc: 0.6670\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7076 - acc: 0.7372 - val_loss: 0.8971 - val_acc: 0.6700\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6684 - acc: 0.7566 - val_loss: 0.8735 - val_acc: 0.6780\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6452 - acc: 0.7598 - val_loss: 0.8332 - val_acc: 0.7140\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6169 - acc: 0.7725 - val_loss: 0.7896 - val_acc: 0.7110\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5958 - acc: 0.7797 - val_loss: 0.8119 - val_acc: 0.7090\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5673 - acc: 0.7906 - val_loss: 0.7788 - val_acc: 0.7270\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5516 - acc: 0.7986 - val_loss: 0.7568 - val_acc: 0.7260\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5364 - acc: 0.8020 - val_loss: 0.7843 - val_acc: 0.7150\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5145 - acc: 0.8109 - val_loss: 0.7725 - val_acc: 0.7370\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.5076 - acc: 0.8114 - val_loss: 0.7257 - val_acc: 0.7400\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4846 - acc: 0.8206 - val_loss: 0.7456 - val_acc: 0.7420\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4763 - acc: 0.8311 - val_loss: 0.7122 - val_acc: 0.7430\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4590 - acc: 0.8266 - val_loss: 0.7689 - val_acc: 0.7310\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4484 - acc: 0.8348 - val_loss: 0.7305 - val_acc: 0.7510\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4323 - acc: 0.8375 - val_loss: 0.7250 - val_acc: 0.7500\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4193 - acc: 0.8443 - val_loss: 0.7311 - val_acc: 0.7450\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.4090 - acc: 0.8486 - val_loss: 0.7318 - val_acc: 0.7480\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3982 - acc: 0.8515 - val_loss: 0.7312 - val_acc: 0.7530\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3875 - acc: 0.8586 - val_loss: 0.7571 - val_acc: 0.7530\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3857 - acc: 0.8562 - val_loss: 0.7039 - val_acc: 0.7520\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3701 - acc: 0.8640 - val_loss: 0.7160 - val_acc: 0.7540\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3659 - acc: 0.8628 - val_loss: 0.7006 - val_acc: 0.7650\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3484 - acc: 0.8711 - val_loss: 0.6902 - val_acc: 0.7600\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3487 - acc: 0.8708 - val_loss: 0.7256 - val_acc: 0.7630\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3308 - acc: 0.8793 - val_loss: 0.7309 - val_acc: 0.7560\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3221 - acc: 0.8836 - val_loss: 0.6828 - val_acc: 0.7640\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3125 - acc: 0.8846 - val_loss: 0.6830 - val_acc: 0.7710\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3020 - acc: 0.8920 - val_loss: 0.7299 - val_acc: 0.7690\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2981 - acc: 0.8936 - val_loss: 0.7395 - val_acc: 0.7570\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2908 - acc: 0.8945 - val_loss: 0.7255 - val_acc: 0.7620\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2846 - acc: 0.8966 - val_loss: 0.7396 - val_acc: 0.7620\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2721 - acc: 0.9023 - val_loss: 0.7198 - val_acc: 0.7680\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2723 - acc: 0.9022 - val_loss: 0.8257 - val_acc: 0.7630\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2679 - acc: 0.9001 - val_loss: 0.7361 - val_acc: 0.7730\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2483 - acc: 0.9090 - val_loss: 0.7817 - val_acc: 0.7570\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2444 - acc: 0.9103 - val_loss: 0.7267 - val_acc: 0.7710\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2472 - acc: 0.9087 - val_loss: 0.7360 - val_acc: 0.7660\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2512 - acc: 0.9075 - val_loss: 0.7642 - val_acc: 0.7740\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2275 - acc: 0.9175 - val_loss: 0.7488 - val_acc: 0.7590\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2236 - acc: 0.9183 - val_loss: 0.7994 - val_acc: 0.7680\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2271 - acc: 0.9182 - val_loss: 0.8282 - val_acc: 0.7590\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2232 - acc: 0.9176 - val_loss: 0.7642 - val_acc: 0.7730\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2109 - acc: 0.9241 - val_loss: 0.7990 - val_acc: 0.7490\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2104 - acc: 0.9250 - val_loss: 0.8029 - val_acc: 0.7680\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2020 - acc: 0.9251 - val_loss: 0.8286 - val_acc: 0.7500\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2006 - acc: 0.9289 - val_loss: 0.7827 - val_acc: 0.7650\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1935 - acc: 0.9308 - val_loss: 0.8464 - val_acc: 0.7530\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1913 - acc: 0.9311 - val_loss: 0.8330 - val_acc: 0.7620\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1864 - acc: 0.9322 - val_loss: 0.9069 - val_acc: 0.7580\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1777 - acc: 0.9357 - val_loss: 0.8737 - val_acc: 0.7620\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1881 - acc: 0.9330 - val_loss: 0.7915 - val_acc: 0.7630\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1747 - acc: 0.9389 - val_loss: 0.8007 - val_acc: 0.7710\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1747 - acc: 0.9357 - val_loss: 0.8244 - val_acc: 0.7650\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1703 - acc: 0.9403 - val_loss: 0.7858 - val_acc: 0.7760\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1609 - acc: 0.9447 - val_loss: 0.8228 - val_acc: 0.7660\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1618 - acc: 0.9431 - val_loss: 0.8555 - val_acc: 0.7700\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1540 - acc: 0.9422 - val_loss: 0.9038 - val_acc: 0.7580\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1544 - acc: 0.9439 - val_loss: 0.8606 - val_acc: 0.7630\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1601 - acc: 0.9419 - val_loss: 0.8901 - val_acc: 0.7570\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1487 - acc: 0.9500 - val_loss: 0.8657 - val_acc: 0.7680\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1475 - acc: 0.9461 - val_loss: 0.8796 - val_acc: 0.7700\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1483 - acc: 0.9461 - val_loss: 0.9519 - val_acc: 0.7540\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1406 - acc: 0.9495 - val_loss: 0.9487 - val_acc: 0.7580\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1454 - acc: 0.9497 - val_loss: 0.8918 - val_acc: 0.7730\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1364 - acc: 0.9524 - val_loss: 0.9025 - val_acc: 0.7670\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1322 - acc: 0.9518 - val_loss: 0.9203 - val_acc: 0.7650\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1331 - acc: 0.9520 - val_loss: 0.9046 - val_acc: 0.7750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmvYxMNh4Xq9",
        "outputId": "be499cc0-4ffd-49ca-da42-413e95595dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate([Xstest, Xqtest], Ytest)[1]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 2ms/step - loss: 0.9046 - acc: 0.7750\n",
            "\n",
            " 테스트 정확도: 0.7750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykCB-E0i4heM",
        "outputId": "96ffefd4-91e8-460d-eb97-6a9d21b07037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# plot accuracy and loss plot\n",
        "plt.subplot(211)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(history.history[\"acc\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(history.history[\"loss\"], color=\"g\", label=\"train\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
        "plt.legend(loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# labels\n",
        "ytest = np.argmax(Ytest, axis=1)\n",
        "\n",
        "# get predictions\n",
        "Ytest_ = model.predict([Xstest, Xqtest])\n",
        "ytest_ = np.argmax(Ytest_, axis=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}