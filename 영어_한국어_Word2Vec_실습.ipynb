{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "영어/한국어 Word2Vec 실습.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPi3vTqPG56+4+eY8dSWuLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIS-SG/ai_lab_224n_NLP/blob/main/%EC%98%81%EC%96%B4_%ED%95%9C%EA%B5%AD%EC%96%B4_Word2Vec_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Mq4RNjsvci"
      },
      "source": [
        "# 딥러닝을 이용한 자연어 처리 입문 - 영어/한국어 Word2Vec 실습\n",
        "#### 참고 자료 : https://wikidocs.net/50739"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtFZRbVBtVcu"
      },
      "source": [
        "# 1. 영어 Word2Vec 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T6_YwG_tvzL"
      },
      "source": [
        "### 1) 훈련 데이터 이해하기\n",
        "##### 얻고자 하는 실질적 데이터는 영어 문장으로만 구성된 <context>와 </context> 사이의 내용이다.\n",
        "##### (Laughter)나 (Applause)와 같은 배경음을 나타내는 단어들을 제거해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpcuqSDNslNX"
      },
      "source": [
        "import re\n",
        "import lxml.etree\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJolsaufvwEP"
      },
      "source": [
        "### 2-1) 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfdWVELdvQcM"
      },
      "source": [
        "import nltk.data\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uChIE3gu6xA"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
        "# 데이터 다운로드\n",
        "\n",
        "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
        "  target_text = etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
        "  parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aCTowoWvIes"
      },
      "source": [
        "# 로드된 데이터 중에서 300개의 글자만 출력\n",
        "parse_text[:300]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_CruvVgvmP_"
      },
      "source": [
        "### 2-2) 전처리 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Nv90q2vreL"
      },
      "source": [
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
        "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
        "\n",
        "sent_text=sent_tokenize(content_text)\n",
        "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
        "\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "     normalized_text.append(tokens)\n",
        "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
        "\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
        "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbxWKrP0v6B9"
      },
      "source": [
        "print('총 샘플의 개수 : {}'.format(len(result)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIpnqw2av-Ce"
      },
      "source": [
        "for line in result[:3]: # 샘플 3개만 출력\n",
        "  print(line) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuJ8z9VCwJ9o"
      },
      "source": [
        "### 3) Word2Vec 훈련시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRFLSOpmwNeR"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nufCWE1hwhLt"
      },
      "source": [
        "\n",
        "\n",
        "1.   size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원\n",
        "2.   window = 컨텍스트 윈도우 크기\n",
        "3.   min_count = 단어 최소 빈도 수 제한(빈도가 적은 단어들은 학습하지 않는다.)\n",
        "4.   workers = 학습을 위한 프로세스 수\n",
        "5.   sg = 0은 CBOW, 1은 Skip-gram.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyEojUlXxozq"
      },
      "source": [
        "# man과 가장 유사한 단어들 출력\n",
        "model_result = model.wv.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SPGYJAzyFyP"
      },
      "source": [
        "### 4) Word2Vec 모델 저장하고 로드하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K6eooo7yOYY"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oMgNSokybto"
      },
      "source": [
        "# 로드한 모델에서 다시 man과 유사한 단어를 출력\n",
        "model_result = loaded_model.most_similar(\"man\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}